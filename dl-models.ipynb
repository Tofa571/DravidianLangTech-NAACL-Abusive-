{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10378334,"sourceType":"datasetVersion","datasetId":6428877},{"sourceId":10603628,"sourceType":"datasetVersion","datasetId":6563746}],"dockerImageVersionId":30839,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nimport keras\nimport transformers\nprint(\"TensorFlow version:\", tf.__version__)\nprint(\"Transformers version:\", transformers.__version__)\nprint(\"Keras version:\", keras.__version__)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T08:53:43.180783Z","iopub.execute_input":"2025-01-29T08:53:43.181132Z","iopub.status.idle":"2025-01-29T08:53:48.074737Z","shell.execute_reply.started":"2025-01-29T08:53:43.181103Z","shell.execute_reply":"2025-01-29T08:53:48.073834Z"}},"outputs":[{"name":"stdout","text":"TensorFlow version: 2.17.1\nTransformers version: 4.47.0\nKeras version: 3.5.0\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import pandas as pd\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\nfrom sklearn.metrics import accuracy_score, precision_recall_fscore_support\nimport numpy as np\nimport torch\nfrom torch.utils.data import Dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T08:53:48.075851Z","iopub.execute_input":"2025-01-29T08:53:48.076558Z","iopub.status.idle":"2025-01-29T08:53:56.187181Z","shell.execute_reply.started":"2025-01-29T08:53:48.076529Z","shell.execute_reply":"2025-01-29T08:53:56.186242Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# Load datasets\ntrain_df = pd.read_csv('/kaggle/input/malayla/AWM_train.csv')\ndev_df = pd.read_csv('/kaggle/input/malayla/AWM_dev.csv')\n# test_without_label = pd.read_csv('/kaggle/input/malayla/AWM_test_without_labels.csv')\ntest_with_label = pd.read_csv('/kaggle/input/test-labell/AWM_test_with_labels (1).csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T08:53:56.189133Z","iopub.execute_input":"2025-01-29T08:53:56.189943Z","iopub.status.idle":"2025-01-29T08:53:56.283162Z","shell.execute_reply.started":"2025-01-29T08:53:56.189912Z","shell.execute_reply":"2025-01-29T08:53:56.282162Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"print(train_df.shape)\nprint(dev_df.shape)\nprint(test_with_label.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T08:53:56.284696Z","iopub.execute_input":"2025-01-29T08:53:56.285070Z","iopub.status.idle":"2025-01-29T08:53:56.291123Z","shell.execute_reply.started":"2025-01-29T08:53:56.285035Z","shell.execute_reply":"2025-01-29T08:53:56.290088Z"}},"outputs":[{"name":"stdout","text":"(2933, 2)\n(629, 2)\n(629, 3)\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"train_df.head(10)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T08:53:56.292160Z","iopub.execute_input":"2025-01-29T08:53:56.292539Z","iopub.status.idle":"2025-01-29T08:53:56.323508Z","shell.execute_reply.started":"2025-01-29T08:53:56.292504Z","shell.execute_reply":"2025-01-29T08:53:56.322316Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"                                                Text        Class\n0  നവ്യയുടെ കയ്യിന്ന് കിട്ടിയതാണല്ലോ. ഇവൾക്ക് അതൊ...      Abusive\n1  \"ഇവരുടെ പ്രശ്നം അസൂയ ആണ്, സുന്ദരികൾ ആയ നടിമാരോ...      Abusive\n2  ചുമ്മാതല്ല ഇവളെ പണ്ട് ലവർ അലക്കി വിട്ടത്...വായ...      Abusive\n3  \"ഒരു സിനിമയിൽ ജഗതി മദാമ്മയായിട്ട് വരുന്നുണ്ടല്...  Non-Abusive\n4  ഈ വർഷത്തെ ബൂലോക തോൽവി പരാജയം അതിനുള്ള ഓസ്‌ക്കാ...      Abusive\n5  ബാക്കിൽ നിക്കുന്ന ചേച്ചി : എന്ത് വെറുപ്പിക്കൽ ...      Abusive\n6  പ്രയാഗ  ശരിക്കും  അമേരിക്കൻ അമ്മായി ലുക്ക് ആയല...  Non-Abusive\n7  പ്രയാഗ ആർന്നോ ഞാൻ വിചാരിച്ചു ഏതോ ഇംഗ്ലീഷ് കാരി...  Non-Abusive\n8  ശെരിക്കും ഇതിന്റെ പാട്ട്  വട്ടാണ് വട്ടാണ് എനിക...  Non-Abusive\n9  നല്ല ഒരു നായിയായിരുന്നു പക്ഷേ ഇപ്പോ ആരും അഭിനയ...      Abusive","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Text</th>\n      <th>Class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>നവ്യയുടെ കയ്യിന്ന് കിട്ടിയതാണല്ലോ. ഇവൾക്ക് അതൊ...</td>\n      <td>Abusive</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>\"ഇവരുടെ പ്രശ്നം അസൂയ ആണ്, സുന്ദരികൾ ആയ നടിമാരോ...</td>\n      <td>Abusive</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ചുമ്മാതല്ല ഇവളെ പണ്ട് ലവർ അലക്കി വിട്ടത്...വായ...</td>\n      <td>Abusive</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>\"ഒരു സിനിമയിൽ ജഗതി മദാമ്മയായിട്ട് വരുന്നുണ്ടല്...</td>\n      <td>Non-Abusive</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ഈ വർഷത്തെ ബൂലോക തോൽവി പരാജയം അതിനുള്ള ഓസ്‌ക്കാ...</td>\n      <td>Abusive</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>ബാക്കിൽ നിക്കുന്ന ചേച്ചി : എന്ത് വെറുപ്പിക്കൽ ...</td>\n      <td>Abusive</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>പ്രയാഗ  ശരിക്കും  അമേരിക്കൻ അമ്മായി ലുക്ക് ആയല...</td>\n      <td>Non-Abusive</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>പ്രയാഗ ആർന്നോ ഞാൻ വിചാരിച്ചു ഏതോ ഇംഗ്ലീഷ് കാരി...</td>\n      <td>Non-Abusive</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>ശെരിക്കും ഇതിന്റെ പാട്ട്  വട്ടാണ് വട്ടാണ് എനിക...</td>\n      <td>Non-Abusive</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>നല്ല ഒരു നായിയായിരുന്നു പക്ഷേ ഇപ്പോ ആരും അഭിനയ...</td>\n      <td>Abusive</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"dev_df.head(10)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T08:53:56.324677Z","iopub.execute_input":"2025-01-29T08:53:56.324999Z","iopub.status.idle":"2025-01-29T08:53:56.334177Z","shell.execute_reply.started":"2025-01-29T08:53:56.324958Z","shell.execute_reply":"2025-01-29T08:53:56.333066Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"                                                Text        Class\n0  ഞാനും എന്റെ ഫാമിലി മോളെ വ്യക്തിത്വവും ഗെയിം കണ...  Non-Abusive\n1  സാരമില്ല മോളെ നീ ആരുടെ മുന്നിലും കരയരുത്  അത് ...  Non-Abusive\n2  ഡോക്ടർക്ക് ഇങ്ങനെ തന്നെ വേണം.  ഈ വിവരമില്ലാത്ത...      Abusive\n3  \"ട്രോളന്മാർക്കും, യൂട്യൂബ് ചാനൽസ് നും ചാകര ആയി .\"  Non-Abusive\n4  ഇപ്പോ പറഞ്ഞ നോ നേര്തെ പറഞ്ഞഗിൽ ഇത്തരം മോശം കമന...  Non-Abusive\n5  നിന്റെ ചേച്ചിമാർ ഓസിന് വോട്ട് പിടിച്ചപ്പോൾ ഓർക...  Non-Abusive\n6  നൈസ് ആയി ഒരു കാരണത്തിനു കാത്ത് നിൽക്കുക ആയിരുന...      Abusive\n7               അന്തം  ഫാൻസിനു  ഇനി  പിരിഞ്ഞു  പോവാം  Non-Abusive\n8  \"ഡോക്ടർ ഇത്രെയും ചീപ്പ്‌ ആയി പോയല്ലോ,,, ഇവന് ന...  Non-Abusive\n9  നല്ല രീതിയിൽ തീരേണ്ട ഒരു കാര്യമായിരുന്നു. ഇപ്പ...  Non-Abusive","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Text</th>\n      <th>Class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ഞാനും എന്റെ ഫാമിലി മോളെ വ്യക്തിത്വവും ഗെയിം കണ...</td>\n      <td>Non-Abusive</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>സാരമില്ല മോളെ നീ ആരുടെ മുന്നിലും കരയരുത്  അത് ...</td>\n      <td>Non-Abusive</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ഡോക്ടർക്ക് ഇങ്ങനെ തന്നെ വേണം.  ഈ വിവരമില്ലാത്ത...</td>\n      <td>Abusive</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>\"ട്രോളന്മാർക്കും, യൂട്യൂബ് ചാനൽസ് നും ചാകര ആയി .\"</td>\n      <td>Non-Abusive</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ഇപ്പോ പറഞ്ഞ നോ നേര്തെ പറഞ്ഞഗിൽ ഇത്തരം മോശം കമന...</td>\n      <td>Non-Abusive</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>നിന്റെ ചേച്ചിമാർ ഓസിന് വോട്ട് പിടിച്ചപ്പോൾ ഓർക...</td>\n      <td>Non-Abusive</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>നൈസ് ആയി ഒരു കാരണത്തിനു കാത്ത് നിൽക്കുക ആയിരുന...</td>\n      <td>Abusive</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>അന്തം  ഫാൻസിനു  ഇനി  പിരിഞ്ഞു  പോവാം</td>\n      <td>Non-Abusive</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>\"ഡോക്ടർ ഇത്രെയും ചീപ്പ്‌ ആയി പോയല്ലോ,,, ഇവന് ന...</td>\n      <td>Non-Abusive</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>നല്ല രീതിയിൽ തീരേണ്ട ഒരു കാര്യമായിരുന്നു. ഇപ്പ...</td>\n      <td>Non-Abusive</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"test_with_label.head(10)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T08:53:56.335143Z","iopub.execute_input":"2025-01-29T08:53:56.335520Z","iopub.status.idle":"2025-01-29T08:53:56.353605Z","shell.execute_reply.started":"2025-01-29T08:53:56.335488Z","shell.execute_reply":"2025-01-29T08:53:56.352568Z"}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"   id                                               Text        Class\n0   1  സൂരജ് നിന്റെ ആര് ആണ് ആള് ഇറക്കി പേടിപ്പിക്കുക ആണോ  Non-Abusive\n1   2  എത്ര അലക്കി വെളുപ്പിച്ചാലും നിനക്കു അർഹത ഇല്ലാ...      Abusive\n2   3  50 ലക്ഷം കയ്യിൽ വയ്ക്കാൻ ഒരിക്കലും യോഗ്യത ഇല്ല...  Non-Abusive\n3   4  \"ബിഗ് ബോസ്സിൽ നിങ്ങളുടെ അഭിനയം എന്തായിരുന്നു,മ...      Abusive\n4   5  അത് അങ്ങനെയാ നമ്മുടെ ഉള്ളിൽ നന്മ ഉണ്ടെങ്കിൽ പട...  Non-Abusive\n5   6  ഇനി കൂടുതൽ ഒന്നും പറയാതിരിക്കുന്നതായിരിക്കും ന...  Non-Abusive\n6   7  നിങ്ങളെ ആരും ഇഷ്ടപ്പെടുന്നില്ലാ നിങ്ങളുടെ കാര്...      Abusive\n7   8  ഈ ഞാൻ ഞാൻ ...... ഞാനെന്താണെന്ന് മനസ്സിലായി ......      Abusive\n8   9                       ഇതിൻ്റെ ട്രോൾ കാണാൻ കേറി വരൂ  Non-Abusive\n9  10      പണത്തിന്റെ കാര്യം വന്നപ്പോൾ ദേഷ്യം ഒക്കെ പോയോ  Non-Abusive","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>Text</th>\n      <th>Class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>സൂരജ് നിന്റെ ആര് ആണ് ആള് ഇറക്കി പേടിപ്പിക്കുക ആണോ</td>\n      <td>Non-Abusive</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>എത്ര അലക്കി വെളുപ്പിച്ചാലും നിനക്കു അർഹത ഇല്ലാ...</td>\n      <td>Abusive</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>50 ലക്ഷം കയ്യിൽ വയ്ക്കാൻ ഒരിക്കലും യോഗ്യത ഇല്ല...</td>\n      <td>Non-Abusive</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>\"ബിഗ് ബോസ്സിൽ നിങ്ങളുടെ അഭിനയം എന്തായിരുന്നു,മ...</td>\n      <td>Abusive</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>അത് അങ്ങനെയാ നമ്മുടെ ഉള്ളിൽ നന്മ ഉണ്ടെങ്കിൽ പട...</td>\n      <td>Non-Abusive</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>6</td>\n      <td>ഇനി കൂടുതൽ ഒന്നും പറയാതിരിക്കുന്നതായിരിക്കും ന...</td>\n      <td>Non-Abusive</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>7</td>\n      <td>നിങ്ങളെ ആരും ഇഷ്ടപ്പെടുന്നില്ലാ നിങ്ങളുടെ കാര്...</td>\n      <td>Abusive</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>8</td>\n      <td>ഈ ഞാൻ ഞാൻ ...... ഞാനെന്താണെന്ന് മനസ്സിലായി ......</td>\n      <td>Abusive</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>9</td>\n      <td>ഇതിൻ്റെ ട്രോൾ കാണാൻ കേറി വരൂ</td>\n      <td>Non-Abusive</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>10</td>\n      <td>പണത്തിന്റെ കാര്യം വന്നപ്പോൾ ദേഷ്യം ഒക്കെ പോയോ</td>\n      <td>Non-Abusive</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"import re\nfrom bs4 import BeautifulSoup\ndef remove_punctuations(text):\n    punctuations = '''!()-[]{};:'\"“\\’,<>./?@#$%^&*_~—॥'''\n    return ''.join([char for char in text if char not in punctuations])\n\n# Function to replace unwanted strings (URLs, emojis, HTML tags, etc.)\ndef replace_strings(text):\n    # Remove URLs\n    url_pattern = r'https?://\\S+|www\\.\\S+'\n    text = re.sub(url_pattern, ' ', text)\n\n    # Remove emojis\n    emoji_pattern = re.compile(\"[\" \n        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n        u\"\\U00002702-\\U000027B0\"\n        u\"\\U000024C2-\\U0001F251\"  \n        u\"\\u2000-\\u206F\"          # general punctuations\n        \"]+\", flags=re.UNICODE)\n    text = emoji_pattern.sub(r' ', text)\n\n    # Remove HTML tags\n    text = BeautifulSoup(text, 'html.parser').get_text()\n\n    # Normalize spaces\n    text = re.sub(r'\\s+', ' ', text)\n\n    return text\n\n# Function for full preprocessing\ndef preprocessing(text):\n    cleaned_text = remove_punctuations(replace_strings(text))\n    return cleaned_text.lower()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T08:53:56.355925Z","iopub.execute_input":"2025-01-29T08:53:56.356188Z","iopub.status.idle":"2025-01-29T08:53:56.662708Z","shell.execute_reply.started":"2025-01-29T08:53:56.356166Z","shell.execute_reply":"2025-01-29T08:53:56.661691Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"# Apply preprocessing to all datasets\ntrain_df['cleanText'] = train_df['Text'].apply(lambda x: preprocessing(str(x)))\ndev_df['cleanText'] = dev_df['Text'].apply(lambda x: preprocessing(str(x)))\ntest_with_label['cleanText'] = test_with_label['Text'].apply(lambda x: preprocessing(str(x)))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T08:54:00.789969Z","iopub.execute_input":"2025-01-29T08:54:00.790807Z","iopub.status.idle":"2025-01-29T08:54:01.166004Z","shell.execute_reply.started":"2025-01-29T08:54:00.790771Z","shell.execute_reply":"2025-01-29T08:54:01.164940Z"}},"outputs":[{"name":"stderr","text":"<ipython-input-9-e98d2e6d74aa>:26: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n  text = BeautifulSoup(text, 'html.parser').get_text()\n<ipython-input-9-e98d2e6d74aa>:26: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n  text = BeautifulSoup(text, 'html.parser').get_text()\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"# Combine all text for vocabulary analysis\ntrain_corpus = train_df['cleanText'].sum()\ndev_corpus = dev_df['cleanText'].sum()\ntest_corpus = test_with_label['cleanText'].sum()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T08:54:01.167229Z","iopub.execute_input":"2025-01-29T08:54:01.167602Z","iopub.status.idle":"2025-01-29T08:54:01.212420Z","shell.execute_reply.started":"2025-01-29T08:54:01.167576Z","shell.execute_reply":"2025-01-29T08:54:01.211205Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"# Vocabulary and OOV analysis\ntrain_vocab = set(train_corpus.split())\ndev_vocab = set(dev_corpus.split())\ntest_vocab = set(test_corpus.split())\n\noov_dev = dev_vocab - train_vocab\noov_test = test_vocab - train_vocab\n\nprint(f\"Number of unique words in training data: {len(train_vocab)}\")\nprint(f\"Number of unique words in development data: {len(dev_vocab)}\")\nprint(f\"Number of unique words in test data: {len(test_vocab)}\")\nprint(f\"OOV words in dev dataset: {len(oov_dev)}\")\nprint(f\"OOV words in test dataset: {len(oov_test)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T08:54:01.568887Z","iopub.execute_input":"2025-01-29T08:54:01.569214Z","iopub.status.idle":"2025-01-29T08:54:01.594002Z","shell.execute_reply.started":"2025-01-29T08:54:01.569189Z","shell.execute_reply":"2025-01-29T08:54:01.593171Z"}},"outputs":[{"name":"stdout","text":"Number of unique words in training data: 15675\nNumber of unique words in development data: 4647\nNumber of unique words in test data: 4586\nOOV words in dev dataset: 2525\nOOV words in test dataset: 2496\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"# Label encoding for train and dev datasets\ntrain_df['enc_label'] = train_df['Class'].replace({'Abusive': 1, 'Non-Abusive': 0})\ndev_df['enc_label'] = dev_df['Class'].replace({'Abusive': 1, 'Non-Abusive': 0})\nprint(\"Training dataset label counts:\")\nprint(train_df['enc_label'].value_counts())\nprint(\"Development dataset label counts:\")\nprint(dev_df['enc_label'].value_counts())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T08:54:03.316872Z","iopub.execute_input":"2025-01-29T08:54:03.317225Z","iopub.status.idle":"2025-01-29T08:54:03.338390Z","shell.execute_reply.started":"2025-01-29T08:54:03.317194Z","shell.execute_reply":"2025-01-29T08:54:03.337502Z"}},"outputs":[{"name":"stdout","text":"Training dataset label counts:\nenc_label\n1    1531\n0    1402\nName: count, dtype: int64\nDevelopment dataset label counts:\nenc_label\n0    326\n1    303\nName: count, dtype: int64\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-13-4654b19dfcb1>:2: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n  train_df['enc_label'] = train_df['Class'].replace({'Abusive': 1, 'Non-Abusive': 0})\n<ipython-input-13-4654b19dfcb1>:3: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n  dev_df['enc_label'] = dev_df['Class'].replace({'Abusive': 1, 'Non-Abusive': 0})\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"import numpy as np\nfrom gensim.models import Word2Vec\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Embedding, Conv1D, MaxPooling1D, Dropout, Dense, Flatten\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom sklearn.metrics import classification_report\n\n# Parameters\nmax_len = 256\nembedding_dim = 128\n\n# Tokenizer Setup\ntokenizer = Tokenizer()\ntokenizer.fit_on_texts(train_df['cleanText'])\nword_index = tokenizer.word_index\nvocab_size = len(word_index) + 1\n\n# Train Word2Vec\ntokenized_sentences = [sentence.split() for sentence in train_df['cleanText']]\nword2vec_model = Word2Vec(sentences=tokenized_sentences, vector_size=embedding_dim, window=5, min_count=1)\n\n# Create Embedding Matrix\nembedding_matrix = np.zeros((vocab_size, embedding_dim))\nfor word, idx in word_index.items():\n    if word in word2vec_model.wv:\n        embedding_matrix[idx] = word2vec_model.wv[word]\n    else:\n        embedding_matrix[idx] = np.random.normal(scale=0.6, size=(embedding_dim,))\n\n# Convert text to padded sequences\nX_train_seq = pad_sequences(tokenizer.texts_to_sequences(train_df['cleanText']), maxlen=max_len, padding='post')\nX_dev_seq = pad_sequences(tokenizer.texts_to_sequences(dev_df['cleanText']), maxlen=max_len, padding='post')\nX_test_seq = pad_sequences(tokenizer.texts_to_sequences(test_with_label['cleanText']), maxlen=max_len, padding='post')\n\n# Convert labels to binary format\ny_train = train_df['enc_label'].values\ny_dev = dev_df['enc_label'].values\ny_true = test_with_label['Class'].replace({'Abusive': 1, 'Non-Abusive': 0}).values\n\n# CNN-Only Model\ncnn_model = Sequential([\n    Embedding(input_dim=vocab_size, output_dim=embedding_dim, weights=[embedding_matrix], input_length=max_len, trainable=False),\n    Conv1D(128, kernel_size=5, activation='relu'),\n    MaxPooling1D(pool_size=2),\n    Dropout(0.5),\n    Conv1D(64, kernel_size=3, activation='relu'),\n    MaxPooling1D(pool_size=2),\n    Dropout(0.5),\n    Flatten(),\n    Dense(64, activation='relu'),\n    Dense(1, activation='sigmoid')\n])\n\ncnn_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n\n# Train CNN Model\nprint(\"\\nTraining CNN Model...\")\ncnn_model.fit(X_train_seq, y_train, epochs=10, batch_size=32, validation_data=(X_dev_seq, y_dev))\n\n# Evaluate CNN Model\nprint(\"\\nEvaluating CNN Model...\")\ny_pred_cnn = (cnn_model.predict(X_test_seq) > 0.5).astype(int)\nprint(\"CNN Classification Report:\\n\", classification_report(y_true, y_pred_cnn))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T07:19:45.526775Z","iopub.execute_input":"2025-01-29T07:19:45.527201Z","iopub.status.idle":"2025-01-29T07:20:33.878908Z","shell.execute_reply.started":"2025-01-29T07:19:45.527162Z","shell.execute_reply":"2025-01-29T07:20:33.877692Z"}},"outputs":[{"name":"stdout","text":"\nTraining CNN Model...\nEpoch 1/10\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-28-21f1ec77f93a>:39: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n  y_true = test_with_label['Class'].replace({'Abusive': 1, 'Non-Abusive': 0}).values\n/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 50ms/step - accuracy: 0.5298 - loss: 0.6924 - val_accuracy: 0.4849 - val_loss: 0.6966\nEpoch 2/10\n\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 48ms/step - accuracy: 0.5386 - loss: 0.6897 - val_accuracy: 0.4849 - val_loss: 0.6951\nEpoch 3/10\n\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 49ms/step - accuracy: 0.5282 - loss: 0.6899 - val_accuracy: 0.4849 - val_loss: 0.6961\nEpoch 4/10\n\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 54ms/step - accuracy: 0.5463 - loss: 0.6878 - val_accuracy: 0.5008 - val_loss: 0.6934\nEpoch 5/10\n\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 47ms/step - accuracy: 0.5549 - loss: 0.6829 - val_accuracy: 0.4881 - val_loss: 0.6969\nEpoch 6/10\n\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 48ms/step - accuracy: 0.5415 - loss: 0.6830 - val_accuracy: 0.5103 - val_loss: 0.6949\nEpoch 7/10\n\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 47ms/step - accuracy: 0.5532 - loss: 0.6817 - val_accuracy: 0.4913 - val_loss: 0.6979\nEpoch 8/10\n\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 48ms/step - accuracy: 0.5464 - loss: 0.6830 - val_accuracy: 0.4992 - val_loss: 0.6991\nEpoch 9/10\n\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 47ms/step - accuracy: 0.5563 - loss: 0.6811 - val_accuracy: 0.4913 - val_loss: 0.7065\nEpoch 10/10\n\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 48ms/step - accuracy: 0.5494 - loss: 0.6788 - val_accuracy: 0.5008 - val_loss: 0.7007\n\nEvaluating CNN Model...\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\nCNN Classification Report:\n               precision    recall  f1-score   support\n\n           0       0.48      0.24      0.32       306\n           1       0.51      0.75      0.61       323\n\n    accuracy                           0.50       629\n   macro avg       0.49      0.50      0.46       629\nweighted avg       0.49      0.50      0.47       629\n\n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"import numpy as np\nfrom gensim.models import FastText\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Embedding, SimpleRNN, Dropout, Dense\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom sklearn.metrics import classification_report\n\n# Parameters\nmax_len = 256\nembedding_dim = 300  # FastText embeddings typically have 300 dimensions\nwindow = 5\nmin_count = 1\n\n# Tokenizer Setup\ntokenizer = Tokenizer()\ntokenizer.fit_on_texts(train_df['cleanText'])\nword_index = tokenizer.word_index\nvocab_size = len(word_index) + 1  # Vocabulary size (+1 for padding token)\n\n# Train FastText on the provided text data \ntokenized_sentences = [sentence.split() for sentence in train_df['cleanText']]\nfasttext_model = FastText(sentences=tokenized_sentences, vector_size=embedding_dim, window=window, min_count=min_count)\n\n# Create Embedding Matrix\nembedding_matrix = np.zeros((vocab_size, embedding_dim))\nfor word, idx in word_index.items():\n    if word in fasttext_model.wv:\n        embedding_matrix[idx] = fasttext_model.wv[word]\n    else:\n        # If the word is not in the FastText model, initialize it randomly\n        embedding_matrix[idx] = np.random.normal(scale=0.6, size=(embedding_dim,))\n\n# Convert text to padded sequences\nX_train_seq = pad_sequences(tokenizer.texts_to_sequences(train_df['cleanText']), maxlen=max_len, padding='post')\nX_dev_seq = pad_sequences(tokenizer.texts_to_sequences(dev_df['cleanText']), maxlen=max_len, padding='post')\nX_test_seq = pad_sequences(tokenizer.texts_to_sequences(test_with_label['cleanText']), maxlen=max_len, padding='post')\n\n# Convert labels to binary format\ny_train = train_df['enc_label'].values\ny_dev = dev_df['enc_label'].values\ny_true = test_with_label['Class'].replace({'Abusive': 1, 'Non-Abusive': 0}).values\n\n# RNN Model with FastText embeddings\nrnn_model = Sequential([\n    Embedding(input_dim=vocab_size, output_dim=embedding_dim, weights=[embedding_matrix], input_length=max_len, trainable=False),\n    SimpleRNN(128, return_sequences=False),  # Simple RNN layer\n    Dropout(0.5), \n    Dense(64, activation='relu'),  \n    Dense(1, activation='sigmoid')  \n])\n\n# Compile the model\nrnn_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n\n# --- Train the RNN Model ---\nprint(\"\\nTraining RNN Model with FastText embeddings...\")\nrnn_model.fit(X_train_seq, y_train, epochs=12, batch_size=32, validation_data=(X_dev_seq, y_dev))\n\n# --- Evaluate the RNN Model ---\nprint(\"\\nEvaluating RNN Model with FastText embeddings...\")\ny_pred_rnn = (rnn_model.predict(X_test_seq) > 0.5).astype(int)\nprint(\"RNN Classification Report:\\n\", classification_report(y_true, y_pred_rnn))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T08:54:13.842312Z","iopub.execute_input":"2025-01-29T08:54:13.842669Z","iopub.status.idle":"2025-01-29T08:55:44.609468Z","shell.execute_reply.started":"2025-01-29T08:54:13.842643Z","shell.execute_reply":"2025-01-29T08:55:44.608191Z"}},"outputs":[{"name":"stderr","text":"<ipython-input-14-eb0bef851404>:42: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n  y_true = test_with_label['Class'].replace({'Abusive': 1, 'Non-Abusive': 0}).values\n/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"\nTraining RNN Model with FastText embeddings...\nEpoch 1/12\n\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 74ms/step - accuracy: 0.5071 - loss: 0.7172 - val_accuracy: 0.4881 - val_loss: 0.7278\nEpoch 2/12\n\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 65ms/step - accuracy: 0.4934 - loss: 0.7431 - val_accuracy: 0.4865 - val_loss: 0.7080\nEpoch 3/12\n\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 65ms/step - accuracy: 0.5086 - loss: 0.7213 - val_accuracy: 0.5056 - val_loss: 0.7063\nEpoch 4/12\n\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 65ms/step - accuracy: 0.4951 - loss: 0.7299 - val_accuracy: 0.5135 - val_loss: 0.7107\nEpoch 5/12\n\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 68ms/step - accuracy: 0.5149 - loss: 0.7192 - val_accuracy: 0.5008 - val_loss: 0.7047\nEpoch 6/12\n\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 67ms/step - accuracy: 0.4969 - loss: 0.7278 - val_accuracy: 0.4881 - val_loss: 0.7245\nEpoch 7/12\n\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 66ms/step - accuracy: 0.5121 - loss: 0.7117 - val_accuracy: 0.5135 - val_loss: 0.6989\nEpoch 8/12\n\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 66ms/step - accuracy: 0.5097 - loss: 0.7121 - val_accuracy: 0.4897 - val_loss: 0.7027\nEpoch 9/12\n\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 65ms/step - accuracy: 0.5203 - loss: 0.7024 - val_accuracy: 0.4801 - val_loss: 0.7177\nEpoch 10/12\n\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 65ms/step - accuracy: 0.5164 - loss: 0.7053 - val_accuracy: 0.5135 - val_loss: 0.6951\nEpoch 11/12\n\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 69ms/step - accuracy: 0.5183 - loss: 0.7017 - val_accuracy: 0.4817 - val_loss: 0.7008\nEpoch 12/12\n\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 67ms/step - accuracy: 0.5034 - loss: 0.7131 - val_accuracy: 0.4833 - val_loss: 0.7195\n\nEvaluating RNN Model with FastText embeddings...\n\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step\nRNN Classification Report:\n               precision    recall  f1-score   support\n\n           0       0.41      0.22      0.29       306\n           1       0.49      0.70      0.57       323\n\n    accuracy                           0.47       629\n   macro avg       0.45      0.46      0.43       629\nweighted avg       0.45      0.47      0.43       629\n\n","output_type":"stream"}],"execution_count":14}]}