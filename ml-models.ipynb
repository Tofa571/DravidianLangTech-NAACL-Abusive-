{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10378491,"sourceType":"datasetVersion","datasetId":6428986},{"sourceId":10603632,"sourceType":"datasetVersion","datasetId":6563750}],"dockerImageVersionId":30839,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nimport keras\nimport transformers\nprint(\"TensorFlow version:\", tf.__version__)\nprint(\"Transformers version:\", transformers.__version__)\nprint(\"Keras version:\", keras.__version__)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-28T17:59:50.360071Z","iopub.execute_input":"2025-01-28T17:59:50.360298Z","iopub.status.idle":"2025-01-28T18:00:10.439503Z","shell.execute_reply.started":"2025-01-28T17:59:50.360275Z","shell.execute_reply":"2025-01-28T18:00:10.438597Z"}},"outputs":[{"name":"stdout","text":"TensorFlow version: 2.17.1\nTransformers version: 4.47.0\nKeras version: 3.5.0\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"\nimport pandas as pd\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\nfrom sklearn.metrics import accuracy_score, precision_recall_fscore_support\nimport numpy as np\nimport torch\nfrom torch.utils.data import Dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-28T18:00:10.440472Z","iopub.execute_input":"2025-01-28T18:00:10.441110Z","iopub.status.idle":"2025-01-28T18:00:18.937834Z","shell.execute_reply.started":"2025-01-28T18:00:10.441080Z","shell.execute_reply":"2025-01-28T18:00:18.936681Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# Load datasets\ntrain_df = pd.read_csv('/kaggle/input/malaylam/AWM_train.csv')\ndev_df = pd.read_csv('/kaggle/input/malaylam/AWM_dev.csv')\n# test_without_label = pd.read_csv('/kaggle/input/malaylam/AWM_test_without_labels.csv')\ntest_with_label = pd.read_csv('/kaggle/input/testlabel-data/AWM_test_with_labels (1).csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-28T18:00:18.939000Z","iopub.execute_input":"2025-01-28T18:00:18.940005Z","iopub.status.idle":"2025-01-28T18:00:19.042174Z","shell.execute_reply.started":"2025-01-28T18:00:18.939974Z","shell.execute_reply":"2025-01-28T18:00:19.041342Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"print(train_df.shape)\nprint(dev_df.shape)\nprint(test_with_label.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-28T18:00:19.044894Z","iopub.execute_input":"2025-01-28T18:00:19.045300Z","iopub.status.idle":"2025-01-28T18:00:19.051152Z","shell.execute_reply.started":"2025-01-28T18:00:19.045251Z","shell.execute_reply":"2025-01-28T18:00:19.050284Z"}},"outputs":[{"name":"stdout","text":"(2933, 2)\n(629, 2)\n(629, 3)\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"train_df.head(10)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-28T18:00:19.055585Z","iopub.execute_input":"2025-01-28T18:00:19.055927Z","iopub.status.idle":"2025-01-28T18:00:19.086859Z","shell.execute_reply.started":"2025-01-28T18:00:19.055888Z","shell.execute_reply":"2025-01-28T18:00:19.085692Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"                                                Text        Class\n0  നവ്യയുടെ കയ്യിന്ന് കിട്ടിയതാണല്ലോ. ഇവൾക്ക് അതൊ...      Abusive\n1  \"ഇവരുടെ പ്രശ്നം അസൂയ ആണ്, സുന്ദരികൾ ആയ നടിമാരോ...      Abusive\n2  ചുമ്മാതല്ല ഇവളെ പണ്ട് ലവർ അലക്കി വിട്ടത്...വായ...      Abusive\n3  \"ഒരു സിനിമയിൽ ജഗതി മദാമ്മയായിട്ട് വരുന്നുണ്ടല്...  Non-Abusive\n4  ഈ വർഷത്തെ ബൂലോക തോൽവി പരാജയം അതിനുള്ള ഓസ്‌ക്കാ...      Abusive\n5  ബാക്കിൽ നിക്കുന്ന ചേച്ചി : എന്ത് വെറുപ്പിക്കൽ ...      Abusive\n6  പ്രയാഗ  ശരിക്കും  അമേരിക്കൻ അമ്മായി ലുക്ക് ആയല...  Non-Abusive\n7  പ്രയാഗ ആർന്നോ ഞാൻ വിചാരിച്ചു ഏതോ ഇംഗ്ലീഷ് കാരി...  Non-Abusive\n8  ശെരിക്കും ഇതിന്റെ പാട്ട്  വട്ടാണ് വട്ടാണ് എനിക...  Non-Abusive\n9  നല്ല ഒരു നായിയായിരുന്നു പക്ഷേ ഇപ്പോ ആരും അഭിനയ...      Abusive","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Text</th>\n      <th>Class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>നവ്യയുടെ കയ്യിന്ന് കിട്ടിയതാണല്ലോ. ഇവൾക്ക് അതൊ...</td>\n      <td>Abusive</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>\"ഇവരുടെ പ്രശ്നം അസൂയ ആണ്, സുന്ദരികൾ ആയ നടിമാരോ...</td>\n      <td>Abusive</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ചുമ്മാതല്ല ഇവളെ പണ്ട് ലവർ അലക്കി വിട്ടത്...വായ...</td>\n      <td>Abusive</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>\"ഒരു സിനിമയിൽ ജഗതി മദാമ്മയായിട്ട് വരുന്നുണ്ടല്...</td>\n      <td>Non-Abusive</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ഈ വർഷത്തെ ബൂലോക തോൽവി പരാജയം അതിനുള്ള ഓസ്‌ക്കാ...</td>\n      <td>Abusive</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>ബാക്കിൽ നിക്കുന്ന ചേച്ചി : എന്ത് വെറുപ്പിക്കൽ ...</td>\n      <td>Abusive</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>പ്രയാഗ  ശരിക്കും  അമേരിക്കൻ അമ്മായി ലുക്ക് ആയല...</td>\n      <td>Non-Abusive</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>പ്രയാഗ ആർന്നോ ഞാൻ വിചാരിച്ചു ഏതോ ഇംഗ്ലീഷ് കാരി...</td>\n      <td>Non-Abusive</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>ശെരിക്കും ഇതിന്റെ പാട്ട്  വട്ടാണ് വട്ടാണ് എനിക...</td>\n      <td>Non-Abusive</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>നല്ല ഒരു നായിയായിരുന്നു പക്ഷേ ഇപ്പോ ആരും അഭിനയ...</td>\n      <td>Abusive</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"dev_df.head(10)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-28T18:00:19.087991Z","iopub.execute_input":"2025-01-28T18:00:19.088339Z","iopub.status.idle":"2025-01-28T18:00:19.098126Z","shell.execute_reply.started":"2025-01-28T18:00:19.088300Z","shell.execute_reply":"2025-01-28T18:00:19.097057Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"                                                Text        Class\n0  ഞാനും എന്റെ ഫാമിലി മോളെ വ്യക്തിത്വവും ഗെയിം കണ...  Non-Abusive\n1  സാരമില്ല മോളെ നീ ആരുടെ മുന്നിലും കരയരുത്  അത് ...  Non-Abusive\n2  ഡോക്ടർക്ക് ഇങ്ങനെ തന്നെ വേണം.  ഈ വിവരമില്ലാത്ത...      Abusive\n3  \"ട്രോളന്മാർക്കും, യൂട്യൂബ് ചാനൽസ് നും ചാകര ആയി .\"  Non-Abusive\n4  ഇപ്പോ പറഞ്ഞ നോ നേര്തെ പറഞ്ഞഗിൽ ഇത്തരം മോശം കമന...  Non-Abusive\n5  നിന്റെ ചേച്ചിമാർ ഓസിന് വോട്ട് പിടിച്ചപ്പോൾ ഓർക...  Non-Abusive\n6  നൈസ് ആയി ഒരു കാരണത്തിനു കാത്ത് നിൽക്കുക ആയിരുന...      Abusive\n7               അന്തം  ഫാൻസിനു  ഇനി  പിരിഞ്ഞു  പോവാം  Non-Abusive\n8  \"ഡോക്ടർ ഇത്രെയും ചീപ്പ്‌ ആയി പോയല്ലോ,,, ഇവന് ന...  Non-Abusive\n9  നല്ല രീതിയിൽ തീരേണ്ട ഒരു കാര്യമായിരുന്നു. ഇപ്പ...  Non-Abusive","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Text</th>\n      <th>Class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ഞാനും എന്റെ ഫാമിലി മോളെ വ്യക്തിത്വവും ഗെയിം കണ...</td>\n      <td>Non-Abusive</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>സാരമില്ല മോളെ നീ ആരുടെ മുന്നിലും കരയരുത്  അത് ...</td>\n      <td>Non-Abusive</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ഡോക്ടർക്ക് ഇങ്ങനെ തന്നെ വേണം.  ഈ വിവരമില്ലാത്ത...</td>\n      <td>Abusive</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>\"ട്രോളന്മാർക്കും, യൂട്യൂബ് ചാനൽസ് നും ചാകര ആയി .\"</td>\n      <td>Non-Abusive</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ഇപ്പോ പറഞ്ഞ നോ നേര്തെ പറഞ്ഞഗിൽ ഇത്തരം മോശം കമന...</td>\n      <td>Non-Abusive</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>നിന്റെ ചേച്ചിമാർ ഓസിന് വോട്ട് പിടിച്ചപ്പോൾ ഓർക...</td>\n      <td>Non-Abusive</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>നൈസ് ആയി ഒരു കാരണത്തിനു കാത്ത് നിൽക്കുക ആയിരുന...</td>\n      <td>Abusive</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>അന്തം  ഫാൻസിനു  ഇനി  പിരിഞ്ഞു  പോവാം</td>\n      <td>Non-Abusive</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>\"ഡോക്ടർ ഇത്രെയും ചീപ്പ്‌ ആയി പോയല്ലോ,,, ഇവന് ന...</td>\n      <td>Non-Abusive</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>നല്ല രീതിയിൽ തീരേണ്ട ഒരു കാര്യമായിരുന്നു. ഇപ്പ...</td>\n      <td>Non-Abusive</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"test_with_label.head(10)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-28T18:00:19.099171Z","iopub.execute_input":"2025-01-28T18:00:19.099505Z","iopub.status.idle":"2025-01-28T18:00:19.120373Z","shell.execute_reply.started":"2025-01-28T18:00:19.099479Z","shell.execute_reply":"2025-01-28T18:00:19.119310Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"   id                                               Text        Class\n0   1  സൂരജ് നിന്റെ ആര് ആണ് ആള് ഇറക്കി പേടിപ്പിക്കുക ആണോ  Non-Abusive\n1   2  എത്ര അലക്കി വെളുപ്പിച്ചാലും നിനക്കു അർഹത ഇല്ലാ...      Abusive\n2   3  50 ലക്ഷം കയ്യിൽ വയ്ക്കാൻ ഒരിക്കലും യോഗ്യത ഇല്ല...  Non-Abusive\n3   4  \"ബിഗ് ബോസ്സിൽ നിങ്ങളുടെ അഭിനയം എന്തായിരുന്നു,മ...      Abusive\n4   5  അത് അങ്ങനെയാ നമ്മുടെ ഉള്ളിൽ നന്മ ഉണ്ടെങ്കിൽ പട...  Non-Abusive\n5   6  ഇനി കൂടുതൽ ഒന്നും പറയാതിരിക്കുന്നതായിരിക്കും ന...  Non-Abusive\n6   7  നിങ്ങളെ ആരും ഇഷ്ടപ്പെടുന്നില്ലാ നിങ്ങളുടെ കാര്...      Abusive\n7   8  ഈ ഞാൻ ഞാൻ ...... ഞാനെന്താണെന്ന് മനസ്സിലായി ......      Abusive\n8   9                       ഇതിൻ്റെ ട്രോൾ കാണാൻ കേറി വരൂ  Non-Abusive\n9  10      പണത്തിന്റെ കാര്യം വന്നപ്പോൾ ദേഷ്യം ഒക്കെ പോയോ  Non-Abusive","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>Text</th>\n      <th>Class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>സൂരജ് നിന്റെ ആര് ആണ് ആള് ഇറക്കി പേടിപ്പിക്കുക ആണോ</td>\n      <td>Non-Abusive</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>എത്ര അലക്കി വെളുപ്പിച്ചാലും നിനക്കു അർഹത ഇല്ലാ...</td>\n      <td>Abusive</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>50 ലക്ഷം കയ്യിൽ വയ്ക്കാൻ ഒരിക്കലും യോഗ്യത ഇല്ല...</td>\n      <td>Non-Abusive</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>\"ബിഗ് ബോസ്സിൽ നിങ്ങളുടെ അഭിനയം എന്തായിരുന്നു,മ...</td>\n      <td>Abusive</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>അത് അങ്ങനെയാ നമ്മുടെ ഉള്ളിൽ നന്മ ഉണ്ടെങ്കിൽ പട...</td>\n      <td>Non-Abusive</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>6</td>\n      <td>ഇനി കൂടുതൽ ഒന്നും പറയാതിരിക്കുന്നതായിരിക്കും ന...</td>\n      <td>Non-Abusive</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>7</td>\n      <td>നിങ്ങളെ ആരും ഇഷ്ടപ്പെടുന്നില്ലാ നിങ്ങളുടെ കാര്...</td>\n      <td>Abusive</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>8</td>\n      <td>ഈ ഞാൻ ഞാൻ ...... ഞാനെന്താണെന്ന് മനസ്സിലായി ......</td>\n      <td>Abusive</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>9</td>\n      <td>ഇതിൻ്റെ ട്രോൾ കാണാൻ കേറി വരൂ</td>\n      <td>Non-Abusive</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>10</td>\n      <td>പണത്തിന്റെ കാര്യം വന്നപ്പോൾ ദേഷ്യം ഒക്കെ പോയോ</td>\n      <td>Non-Abusive</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"import re\nfrom bs4 import BeautifulSoup\ndef remove_punctuations(text):\n    punctuations = '''!()-[]{};:'\"“\\’,<>./?@#$%^&*_~—॥'''\n    return ''.join([char for char in text if char not in punctuations])\n\n# Function to replace unwanted strings (URLs, emojis, HTML tags, etc.)\ndef replace_strings(text):\n    # Remove URLs\n    url_pattern = r'https?://\\S+|www\\.\\S+'\n    text = re.sub(url_pattern, ' ', text)\n\n    # Remove emojis\n    emoji_pattern = re.compile(\"[\" \n        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n        u\"\\U00002702-\\U000027B0\"\n        u\"\\U000024C2-\\U0001F251\"  \n        u\"\\u2000-\\u206F\"          # general punctuations\n        \"]+\", flags=re.UNICODE)\n    text = emoji_pattern.sub(r' ', text)\n\n    # Remove HTML tags\n    text = BeautifulSoup(text, 'html.parser').get_text()\n\n    # Normalize spaces\n    text = re.sub(r'\\s+', ' ', text)\n\n    return text\n\n# Function for full preprocessing\ndef preprocessing(text):\n    cleaned_text = remove_punctuations(replace_strings(text))\n    return cleaned_text.lower()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-28T18:00:19.121489Z","iopub.execute_input":"2025-01-28T18:00:19.121871Z","iopub.status.idle":"2025-01-28T18:00:19.432696Z","shell.execute_reply.started":"2025-01-28T18:00:19.121831Z","shell.execute_reply":"2025-01-28T18:00:19.431582Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"# Apply preprocessing to all datasets\ntrain_df['cleanText'] = train_df['Text'].apply(lambda x: preprocessing(str(x)))\ndev_df['cleanText'] = dev_df['Text'].apply(lambda x: preprocessing(str(x)))\ntest_with_label['cleanText'] = test_with_label['Text'].apply(lambda x: preprocessing(str(x)))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-28T18:00:19.433843Z","iopub.execute_input":"2025-01-28T18:00:19.434574Z","iopub.status.idle":"2025-01-28T18:00:19.834624Z","shell.execute_reply.started":"2025-01-28T18:00:19.434541Z","shell.execute_reply":"2025-01-28T18:00:19.833485Z"}},"outputs":[{"name":"stderr","text":"<ipython-input-8-e98d2e6d74aa>:26: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n  text = BeautifulSoup(text, 'html.parser').get_text()\n<ipython-input-8-e98d2e6d74aa>:26: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n  text = BeautifulSoup(text, 'html.parser').get_text()\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"# Combine all text for vocabulary analysis\ntrain_corpus = train_df['cleanText'].sum()\ndev_corpus = dev_df['cleanText'].sum()\ntest_corpus = test_with_label['cleanText'].sum()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-28T18:00:19.835544Z","iopub.execute_input":"2025-01-28T18:00:19.835842Z","iopub.status.idle":"2025-01-28T18:00:19.892737Z","shell.execute_reply.started":"2025-01-28T18:00:19.835820Z","shell.execute_reply":"2025-01-28T18:00:19.891574Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"# Vocabulary and OOV analysis\ntrain_vocab = set(train_corpus.split())\ndev_vocab = set(dev_corpus.split())\ntest_vocab = set(test_corpus.split())\n\noov_dev = dev_vocab - train_vocab\noov_test = test_vocab - train_vocab\n\nprint(f\"Number of unique words in training data: {len(train_vocab)}\")\nprint(f\"Number of unique words in development data: {len(dev_vocab)}\")\nprint(f\"Number of unique words in test data: {len(test_vocab)}\")\nprint(f\"OOV words in dev dataset: {len(oov_dev)}\")\nprint(f\"OOV words in test dataset: {len(oov_test)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-28T18:00:19.893692Z","iopub.execute_input":"2025-01-28T18:00:19.893949Z","iopub.status.idle":"2025-01-28T18:00:19.931329Z","shell.execute_reply.started":"2025-01-28T18:00:19.893927Z","shell.execute_reply":"2025-01-28T18:00:19.930371Z"}},"outputs":[{"name":"stdout","text":"Number of unique words in training data: 15675\nNumber of unique words in development data: 4647\nNumber of unique words in test data: 4586\nOOV words in dev dataset: 2525\nOOV words in test dataset: 2496\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"# Label encoding for train, dev, and test datasets\ntrain_df['enc_label'] = train_df['Class'].replace({'Abusive': 1, 'Non-Abusive': 0})\ndev_df['enc_label'] = dev_df['Class'].replace({'Abusive': 1, 'Non-Abusive': 0})\ntest_with_label['enc_label'] = test_with_label['Class'].replace({'Abusive': 1, 'Non-Abusive': 0})\n\nprint(\"Training dataset label counts:\")\nprint(train_df['enc_label'].value_counts())\nprint(\"Development dataset label counts:\")\nprint(dev_df['enc_label'].value_counts())\nprint(\"Test dataset label counts:\")\nprint(test_with_label['enc_label'].value_counts())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-28T18:02:58.300168Z","iopub.execute_input":"2025-01-28T18:02:58.300597Z","iopub.status.idle":"2025-01-28T18:02:58.317452Z","shell.execute_reply.started":"2025-01-28T18:02:58.300563Z","shell.execute_reply":"2025-01-28T18:02:58.316054Z"}},"outputs":[{"name":"stdout","text":"Training dataset label counts:\nenc_label\n1    1531\n0    1402\nName: count, dtype: int64\nDevelopment dataset label counts:\nenc_label\n0    326\n1    303\nName: count, dtype: int64\nTest dataset label counts:\nenc_label\n1    323\n0    306\nName: count, dtype: int64\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-15-f9d929a275b1>:2: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n  train_df['enc_label'] = train_df['Class'].replace({'Abusive': 1, 'Non-Abusive': 0})\n<ipython-input-15-f9d929a275b1>:3: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n  dev_df['enc_label'] = dev_df['Class'].replace({'Abusive': 1, 'Non-Abusive': 0})\n<ipython-input-15-f9d929a275b1>:4: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n  test_with_label['enc_label'] = test_with_label['Class'].replace({'Abusive': 1, 'Non-Abusive': 0})\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import VotingClassifier\nfrom sklearn.metrics import classification_report, accuracy_score\nimport numpy as np\n\n# TF-IDF Vectorizer\ntfidf_vectorizer = TfidfVectorizer(max_features=5000)\nX_train_tfidf = tfidf_vectorizer.fit_transform(train_df['cleanText'])\nX_test_tfidf = tfidf_vectorizer.transform(test_with_label['cleanText'])\n\ny_train = train_df['enc_label']\ny_test = test_with_label['enc_label']\n\n# Individual models\nmodels = {\n    \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=42),\n    \"Naive Bayes\": MultinomialNB(),\n    \"SVM\": SVC(kernel='linear', C=1, probability=True),  # Enable probability for ensemble\n    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42),\n}\n\n# Train and evaluate individual models\nfor name, model in models.items():\n    print(f\"Training {name}...\")\n    model.fit(X_train_tfidf, y_train)\n    \n    # Evaluation on Test Set\n    y_test_pred = model.predict(X_test_tfidf)\n    print(f\"Classification Report for Test Set ({name}):\")\n    print(classification_report(y_test, y_test_pred))\n    print(\"\\n\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-28T18:03:01.406167Z","iopub.execute_input":"2025-01-28T18:03:01.406537Z","iopub.status.idle":"2025-01-28T18:03:08.229333Z","shell.execute_reply.started":"2025-01-28T18:03:01.406509Z","shell.execute_reply":"2025-01-28T18:03:08.227993Z"}},"outputs":[{"name":"stdout","text":"Training Logistic Regression...\nClassification Report for Test Set (Logistic Regression):\n              precision    recall  f1-score   support\n\n           0       0.62      0.66      0.64       306\n           1       0.66      0.61      0.63       323\n\n    accuracy                           0.64       629\n   macro avg       0.64      0.64      0.64       629\nweighted avg       0.64      0.64      0.64       629\n\n\n\nTraining Naive Bayes...\nClassification Report for Test Set (Naive Bayes):\n              precision    recall  f1-score   support\n\n           0       0.63      0.67      0.65       306\n           1       0.67      0.63      0.65       323\n\n    accuracy                           0.65       629\n   macro avg       0.65      0.65      0.65       629\nweighted avg       0.65      0.65      0.65       629\n\n\n\nTraining SVM...\nClassification Report for Test Set (SVM):\n              precision    recall  f1-score   support\n\n           0       0.63      0.68      0.65       306\n           1       0.67      0.62      0.64       323\n\n    accuracy                           0.65       629\n   macro avg       0.65      0.65      0.65       629\nweighted avg       0.65      0.65      0.65       629\n\n\n\nTraining Random Forest...\nClassification Report for Test Set (Random Forest):\n              precision    recall  f1-score   support\n\n           0       0.59      0.65      0.61       306\n           1       0.63      0.57      0.60       323\n\n    accuracy                           0.61       629\n   macro avg       0.61      0.61      0.61       629\nweighted avg       0.61      0.61      0.61       629\n\n\n\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"# Ensemble technique: Majority Voting\nprint(\"Training Ensemble Model with Majority Voting...\")\n\n# Create an ensemble with Logistic Regression, Naive Bayes, and SVM\nensemble_model = VotingClassifier(\n    estimators=[\n        ('lr', LogisticRegression(max_iter=1000, random_state=42)),\n        ('nb', MultinomialNB()),\n        ('svm', SVC(kernel='linear', C=1, probability=True))\n    ],\n    voting='soft'  # soft voting for better probabilities\n)\n\nensemble_model.fit(X_train_tfidf, y_train)\ny_test_ensemble_pred = ensemble_model.predict(X_test_tfidf)\n\n# Classification report for the ensemble model\nprint(\"Classification Report for Test Set (Ensemble Model - Majority Voting):\")\nprint(classification_report(y_test, y_test_ensemble_pred))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-28T18:09:18.358767Z","iopub.execute_input":"2025-01-28T18:09:18.359099Z","iopub.status.idle":"2025-01-28T18:09:23.263711Z","shell.execute_reply.started":"2025-01-28T18:09:18.359074Z","shell.execute_reply":"2025-01-28T18:09:23.262595Z"}},"outputs":[{"name":"stdout","text":"Training Ensemble Model with Majority Voting...\nClassification Report for Test Set (Ensemble Model - Majority Voting):\n              precision    recall  f1-score   support\n\n           0       0.63      0.67      0.65       306\n           1       0.67      0.62      0.64       323\n\n    accuracy                           0.65       629\n   macro avg       0.65      0.65      0.65       629\nweighted avg       0.65      0.65      0.65       629\n\n","output_type":"stream"}],"execution_count":21}]}