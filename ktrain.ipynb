{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10270030,"sourceType":"datasetVersion","datasetId":6354147},{"sourceId":10607373,"sourceType":"datasetVersion","datasetId":6566394}],"dockerImageVersionId":30840,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**Ktrain Hate-speech-CNERG/indic-abusive-allInOne-MuRIL**","metadata":{}},{"cell_type":"code","source":"pip install --upgrade tensorflow","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T09:01:47.722257Z","iopub.execute_input":"2025-01-29T09:01:47.722484Z","iopub.status.idle":"2025-01-29T09:03:20.061444Z","shell.execute_reply.started":"2025-01-29T09:01:47.722462Z","shell.execute_reply":"2025-01-29T09:03:20.060471Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.1)\nCollecting tensorflow\n  Downloading tensorflow-2.18.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\nRequirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\nRequirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\nRequirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\nRequirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\nRequirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\nRequirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\nRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.2)\nRequirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\nRequirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (75.1.0)\nRequirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.17.0)\nRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.5.0)\nRequirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\nRequirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.17.0)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.68.1)\nCollecting tensorboard<2.19,>=2.18 (from tensorflow)\n  Downloading tensorboard-2.18.0-py3-none-any.whl.metadata (1.6 kB)\nRequirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.5.0)\nRequirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.26.4)\nRequirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.12.1)\nRequirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.1)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\nRequirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\nRequirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.5.0->tensorflow) (0.0.8)\nRequirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.5.0->tensorflow) (0.13.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy<2.1.0,>=1.26.0->tensorflow) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy<2.1.0,>=1.26.0->tensorflow) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy<2.1.0,>=1.26.0->tensorflow) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy<2.1.0,>=1.26.0->tensorflow) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy<2.1.0,>=1.26.0->tensorflow) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy<2.1.0,>=1.26.0->tensorflow) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.0)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.12.14)\nRequirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<2.1.0,>=1.26.0->tensorflow) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<2.1.0,>=1.26.0->tensorflow) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy<2.1.0,>=1.26.0->tensorflow) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy<2.1.0,>=1.26.0->tensorflow) (2024.2.0)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy<2.1.0,>=1.26.0->tensorflow) (2024.2.0)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\nDownloading tensorflow-2.18.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (615.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m615.3/615.3 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading tensorboard-2.18.0-py3-none-any.whl (5.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: tensorboard, tensorflow\n  Attempting uninstall: tensorboard\n    Found existing installation: tensorboard 2.17.1\n    Uninstalling tensorboard-2.17.1:\n      Successfully uninstalled tensorboard-2.17.1\n  Attempting uninstall: tensorflow\n    Found existing installation: tensorflow 2.17.1\n    Uninstalling tensorflow-2.17.1:\n      Successfully uninstalled tensorflow-2.17.1\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntensorflow-decision-forests 1.10.0 requires tensorflow==2.17.0, but you have tensorflow 2.18.0 which is incompatible.\ntensorflow-text 2.17.0 requires tensorflow<2.18,>=2.17.0, but you have tensorflow 2.18.0 which is incompatible.\ntf-keras 2.17.0 requires tensorflow<2.18,>=2.17, but you have tensorflow 2.18.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed tensorboard-2.18.0 tensorflow-2.18.0\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"pip uninstall tensorflow keras ktrain -y","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T09:03:20.065346Z","iopub.execute_input":"2025-01-29T09:03:20.065564Z","iopub.status.idle":"2025-01-29T09:03:23.836411Z","shell.execute_reply.started":"2025-01-29T09:03:20.065542Z","shell.execute_reply":"2025-01-29T09:03:23.835585Z"}},"outputs":[{"name":"stdout","text":"Found existing installation: tensorflow 2.18.0\nUninstalling tensorflow-2.18.0:\n  Successfully uninstalled tensorflow-2.18.0\nFound existing installation: keras 3.5.0\nUninstalling keras-3.5.0:\n  Successfully uninstalled keras-3.5.0\n\u001b[33mWARNING: Skipping ktrain as it is not installed.\u001b[0m\u001b[33m\n\u001b[0mNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"!pip install tensorflow==2.11 keras==2.11 ktrain transformers==4.28.1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T09:03:23.837380Z","iopub.execute_input":"2025-01-29T09:03:23.837681Z","iopub.status.idle":"2025-01-29T09:05:00.300305Z","shell.execute_reply.started":"2025-01-29T09:03:23.837647Z","shell.execute_reply":"2025-01-29T09:05:00.299396Z"}},"outputs":[{"name":"stdout","text":"Collecting tensorflow==2.11\n  Downloading tensorflow-2.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.1 kB)\nCollecting keras==2.11\n  Downloading keras-2.11.0-py2.py3-none-any.whl.metadata (1.4 kB)\nCollecting ktrain\n  Downloading ktrain-0.41.4.tar.gz (25.3 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m25.3/25.3 MB\u001b[0m \u001b[31m73.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nCollecting transformers==4.28.1\n  Downloading transformers-4.28.1-py3-none-any.whl.metadata (109 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.0/110.0 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11) (1.4.0)\nRequirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11) (1.6.3)\nRequirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11) (24.3.25)\nCollecting gast<=0.4.0,>=0.2.1 (from tensorflow==2.11)\n  Downloading gast-0.4.0-py3-none-any.whl.metadata (1.1 kB)\nRequirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11) (0.2.0)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11) (1.68.1)\nRequirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11) (3.12.1)\nRequirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11) (18.1.1)\nRequirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11) (1.26.4)\nRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11) (3.4.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11) (24.2)\nCollecting protobuf<3.20,>=3.9.2 (from tensorflow==2.11)\n  Downloading protobuf-3.19.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (787 bytes)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11) (75.1.0)\nRequirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11) (1.17.0)\nCollecting tensorboard<2.12,>=2.11 (from tensorflow==2.11)\n  Downloading tensorboard-2.11.2-py3-none-any.whl.metadata (1.9 kB)\nCollecting tensorflow-estimator<2.12,>=2.11.0 (from tensorflow==2.11)\n  Downloading tensorflow_estimator-2.11.0-py2.py3-none-any.whl.metadata (1.3 kB)\nRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11) (2.5.0)\nRequirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11) (4.12.2)\nRequirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11) (1.17.0)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11) (0.37.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.1) (3.16.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.1) (0.27.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.1) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.1) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.1) (2.32.3)\nCollecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers==4.28.1)\n  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.1) (4.67.1)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from ktrain) (1.2.2)\nRequirement already satisfied: matplotlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from ktrain) (3.7.5)\nRequirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from ktrain) (2.2.2)\nRequirement already satisfied: fastprogress>=0.1.21 in /usr/local/lib/python3.10/dist-packages (from ktrain) (1.0.3)\nRequirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from ktrain) (1.4.2)\nCollecting langdetect (from ktrain)\n  Downloading langdetect-1.0.9.tar.gz (981 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m41.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: jieba in /usr/local/lib/python3.10/dist-packages (from ktrain) (0.42.1)\nRequirement already satisfied: charset-normalizer in /usr/local/lib/python3.10/dist-packages (from ktrain) (3.4.0)\nRequirement already satisfied: chardet in /usr/local/lib/python3.10/dist-packages (from ktrain) (5.2.0)\nCollecting syntok>1.3.3 (from ktrain)\n  Downloading syntok-1.4.4-py3-none-any.whl.metadata (10 kB)\nCollecting tika (from ktrain)\n  Downloading tika-2.6.0.tar.gz (27 kB)\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from ktrain) (0.2.0)\nCollecting keras_bert>=0.86.0 (from ktrain)\n  Downloading keras-bert-0.89.0.tar.gz (25 kB)\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nCollecting whoosh (from ktrain)\n  Downloading Whoosh-2.7.4-py2.py3-none-any.whl.metadata (3.1 kB)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow==2.11) (0.45.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers==4.28.1) (2024.9.0)\nCollecting keras-transformer==0.40.0 (from keras_bert>=0.86.0->ktrain)\n  Downloading keras-transformer-0.40.0.tar.gz (9.7 kB)\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nCollecting keras-pos-embd==0.13.0 (from keras-transformer==0.40.0->keras_bert>=0.86.0->ktrain)\n  Downloading keras-pos-embd-0.13.0.tar.gz (5.6 kB)\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nCollecting keras-multi-head==0.29.0 (from keras-transformer==0.40.0->keras_bert>=0.86.0->ktrain)\n  Downloading keras-multi-head-0.29.0.tar.gz (13 kB)\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nCollecting keras-layer-normalization==0.16.0 (from keras-transformer==0.40.0->keras_bert>=0.86.0->ktrain)\n  Downloading keras-layer-normalization-0.16.0.tar.gz (3.9 kB)\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nCollecting keras-position-wise-feed-forward==0.8.0 (from keras-transformer==0.40.0->keras_bert>=0.86.0->ktrain)\n  Downloading keras-position-wise-feed-forward-0.8.0.tar.gz (4.1 kB)\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nCollecting keras-embed-sim==0.10.0 (from keras-transformer==0.40.0->keras_bert>=0.86.0->ktrain)\n  Downloading keras-embed-sim-0.10.0.tar.gz (3.6 kB)\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nCollecting keras-self-attention==0.51.0 (from keras-multi-head==0.29.0->keras-transformer==0.40.0->keras_bert>=0.86.0->ktrain)\n  Downloading keras-self-attention-0.51.0.tar.gz (11 kB)\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->ktrain) (1.3.1)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->ktrain) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->ktrain) (4.55.3)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->ktrain) (1.4.7)\nRequirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->ktrain) (11.0.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->ktrain) (3.2.0)\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->ktrain) (2.8.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.20->tensorflow==2.11) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.20->tensorflow==2.11) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.20->tensorflow==2.11) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.20->tensorflow==2.11) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.20->tensorflow==2.11) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.20->tensorflow==2.11) (2.4.1)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.1->ktrain) (2024.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.1->ktrain) (2024.2)\nRequirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.12,>=2.11->tensorflow==2.11) (2.27.0)\nCollecting google-auth-oauthlib<0.5,>=0.4.1 (from tensorboard<2.12,>=2.11->tensorflow==2.11)\n  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl.metadata (2.7 kB)\nRequirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.12,>=2.11->tensorflow==2.11) (3.7)\nCollecting tensorboard-data-server<0.7.0,>=0.6.0 (from tensorboard<2.12,>=2.11->tensorflow==2.11)\n  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl.metadata (1.1 kB)\nCollecting tensorboard-plugin-wit>=1.6.0 (from tensorboard<2.12,>=2.11->tensorflow==2.11)\n  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl.metadata (873 bytes)\nRequirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.12,>=2.11->tensorflow==2.11) (3.1.3)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.28.1) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.28.1) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.28.1) (2024.12.14)\nRequirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->ktrain) (1.13.1)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->ktrain) (3.5.0)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow==2.11) (5.5.0)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow==2.11) (0.4.1)\nRequirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow==2.11) (4.9)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow==2.11) (1.3.1)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.12,>=2.11->tensorflow==2.11) (3.0.2)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.20->tensorflow==2.11) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.20->tensorflow==2.11) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.20->tensorflow==2.11) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.20->tensorflow==2.11) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.20->tensorflow==2.11) (2024.2.0)\nRequirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow==2.11) (0.6.1)\nRequirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow==2.11) (3.2.2)\nDownloading tensorflow-2.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (588.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m588.3/588.3 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading keras-2.11.0-py2.py3-none-any.whl (1.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m59.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading transformers-4.28.1-py3-none-any.whl (7.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m92.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading gast-0.4.0-py3-none-any.whl (9.8 kB)\nDownloading protobuf-3.19.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m39.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading syntok-1.4.4-py3-none-any.whl (24 kB)\nDownloading tensorboard-2.11.2-py3-none-any.whl (6.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m103.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading tensorflow_estimator-2.11.0-py2.py3-none-any.whl (439 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m439.2/439.2 kB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m96.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading Whoosh-2.7.4-py2.py3-none-any.whl (468 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m468.8/468.8 kB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\nDownloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m84.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.3/781.3 kB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: ktrain, keras_bert, keras-transformer, keras-embed-sim, keras-layer-normalization, keras-multi-head, keras-pos-embd, keras-position-wise-feed-forward, keras-self-attention, langdetect, tika\n  Building wheel for ktrain (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for ktrain: filename=ktrain-0.41.4-py3-none-any.whl size=25316932 sha256=6e0c1bd14da1157ec7c46ba2cb907d4b0429b629dde806b263f254f66b843595\n  Stored in directory: /root/.cache/pip/wheels/fa/6a/9c/8a873b38bbd8bc207d33c64726bd18f7ef85f8e70dc3ac2e4b\n  Building wheel for keras_bert (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for keras_bert: filename=keras_bert-0.89.0-py3-none-any.whl size=33500 sha256=9cc6683fc767183da460e0cf588f278042174c4f40b41b97301f23ddd9bf7998\n  Stored in directory: /root/.cache/pip/wheels/89/0c/04/646b6fdf6375911b42c8d540a8a3fda8d5d77634e5dcbe7b26\n  Building wheel for keras-transformer (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for keras-transformer: filename=keras_transformer-0.40.0-py3-none-any.whl size=12285 sha256=f6833d0f5e60224b3c242377341b346f63d79b172dc96bd7510872511676cd78\n  Stored in directory: /root/.cache/pip/wheels/f2/cb/22/75a0ad376129177f7c95c0d91331a18f5368fd657f4035ba7c\n  Building wheel for keras-embed-sim (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for keras-embed-sim: filename=keras_embed_sim-0.10.0-py3-none-any.whl size=3944 sha256=0e5a2cde8a756614552912de69d0f428c2b8236664108d48bb0e75a2e9b75417\n  Stored in directory: /root/.cache/pip/wheels/82/32/c7/fd35d0d1b840a6c7cbd4343f808d10d0f7b87d271a4dbe796f\n  Building wheel for keras-layer-normalization (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for keras-layer-normalization: filename=keras_layer_normalization-0.16.0-py3-none-any.whl size=4654 sha256=91dd4d325f18d932e8487b7fd72a513962451e916429d1521f02cbaa7492a55b\n  Stored in directory: /root/.cache/pip/wheels/ed/3a/4b/21db23c0cc56c4b219616e181f258eb7c57d36cc5d056fae9a\n  Building wheel for keras-multi-head (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for keras-multi-head: filename=keras_multi_head-0.29.0-py3-none-any.whl size=14974 sha256=337f61bb1c9d12cfb1a35f49d2e6579d0b7bdd02e26a3b7721bbe9fa1c8cf044\n  Stored in directory: /root/.cache/pip/wheels/cb/23/4b/06d7ae21714f70fcc25b48f972cc8e5e7f4b6b764a038b509d\n  Building wheel for keras-pos-embd (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for keras-pos-embd: filename=keras_pos_embd-0.13.0-py3-none-any.whl size=6945 sha256=18a54faba69047a571813d3bc7718d42c25f2e6f823e61c895dab76d1f90a162\n  Stored in directory: /root/.cache/pip/wheels/78/07/1b/b1ca47b6ac338554b75c8f52c54e6a2bfbe1b07d79579979a4\n  Building wheel for keras-position-wise-feed-forward (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for keras-position-wise-feed-forward: filename=keras_position_wise_feed_forward-0.8.0-py3-none-any.whl size=4970 sha256=671d24f35b7b2f154312cbcba9e38ce8b7758b9c940d634c55b5e7cf25344e77\n  Stored in directory: /root/.cache/pip/wheels/c1/6a/04/d1706a53b23b2cb5f9a0a76269bf87925daa1bca09eac01b21\n  Building wheel for keras-self-attention (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for keras-self-attention: filename=keras_self_attention-0.51.0-py3-none-any.whl size=18895 sha256=8c4aaa0e601a194622ddf691a05e9af3f48b8ee37ef5ab5811a6394c3306b83d\n  Stored in directory: /root/.cache/pip/wheels/b8/f7/24/607b483144fb9c47b4ba2c5fba6b68e54aeee2d5bf6c05302e\n  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993222 sha256=b4d0c41ff6ebef250e2b41650d3b12f3c38b2cffbd4a60d6f6e35c9f23ec4594\n  Stored in directory: /root/.cache/pip/wheels/95/03/7d/59ea870c70ce4e5a370638b5462a7711ab78fba2f655d05106\n  Building wheel for tika (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for tika: filename=tika-2.6.0-py3-none-any.whl size=32624 sha256=9f4987a58d89984a4ef03bfe19e57ba7b03a87f2ff3f469a635f578920aa5791\n  Stored in directory: /root/.cache/pip/wheels/5f/71/c7/b757709531121b1700cffda5b6b0d4aad095fb507ec84316d0\nSuccessfully built ktrain keras_bert keras-transformer keras-embed-sim keras-layer-normalization keras-multi-head keras-pos-embd keras-position-wise-feed-forward keras-self-attention langdetect tika\nInstalling collected packages: whoosh, tokenizers, tensorboard-plugin-wit, tensorflow-estimator, tensorboard-data-server, syntok, protobuf, langdetect, keras, gast, tika, google-auth-oauthlib, keras-self-attention, keras-position-wise-feed-forward, keras-pos-embd, keras-multi-head, keras-layer-normalization, keras-embed-sim, keras-transformer, transformers, tensorboard, keras_bert, tensorflow, ktrain\n  Attempting uninstall: tokenizers\n    Found existing installation: tokenizers 0.21.0\n    Uninstalling tokenizers-0.21.0:\n      Successfully uninstalled tokenizers-0.21.0\n  Attempting uninstall: tensorboard-data-server\n    Found existing installation: tensorboard-data-server 0.7.2\n    Uninstalling tensorboard-data-server-0.7.2:\n      Successfully uninstalled tensorboard-data-server-0.7.2\n  Attempting uninstall: protobuf\n    Found existing installation: protobuf 3.20.3\n    Uninstalling protobuf-3.20.3:\n      Successfully uninstalled protobuf-3.20.3\n  Attempting uninstall: gast\n    Found existing installation: gast 0.6.0\n    Uninstalling gast-0.6.0:\n      Successfully uninstalled gast-0.6.0\n  Attempting uninstall: google-auth-oauthlib\n    Found existing installation: google-auth-oauthlib 1.2.1\n    Uninstalling google-auth-oauthlib-1.2.1:\n      Successfully uninstalled google-auth-oauthlib-1.2.1\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.47.0\n    Uninstalling transformers-4.47.0:\n      Successfully uninstalled transformers-4.47.0\n  Attempting uninstall: tensorboard\n    Found existing installation: tensorboard 2.18.0\n    Uninstalling tensorboard-2.18.0:\n      Successfully uninstalled tensorboard-2.18.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ngcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\ngoogle-ai-generativelanguage 0.6.10 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\ngoogle-cloud-aiplatform 1.74.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\ngoogle-cloud-bigquery-connection 1.17.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\ngoogle-cloud-bigtable 2.27.0 requires google-api-core[grpc]<3.0.0dev,>=2.16.0, but you have google-api-core 1.34.1 which is incompatible.\ngoogle-cloud-bigtable 2.27.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\ngoogle-cloud-datastore 2.20.2 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\ngoogle-cloud-firestore 2.19.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\ngoogle-cloud-functions 1.19.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\ngoogle-cloud-iam 2.17.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\ngoogle-cloud-language 2.16.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\ngoogle-cloud-pubsub 2.27.1 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\ngoogle-cloud-resource-manager 1.14.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\ngoogle-cloud-videointelligence 2.15.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\ngoogle-cloud-vision 3.9.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\ngoogleapis-common-protos 1.66.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0.dev0,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\ngrpc-google-iam-v1 0.13.1 requires protobuf!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\nkaggle-environments 1.16.10 requires transformers>=4.33.1, but you have transformers 4.28.1 which is incompatible.\nonnx 1.17.0 requires protobuf>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\npandas-gbq 0.25.0 requires google-api-core<3.0.0dev,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\npandas-gbq 0.25.0 requires google-auth-oauthlib>=0.7.0, but you have google-auth-oauthlib 0.4.6 which is incompatible.\nsentence-transformers 3.3.1 requires transformers<5.0.0,>=4.41.0, but you have transformers 4.28.1 which is incompatible.\ntensorflow-datasets 4.9.7 requires protobuf>=3.20, but you have protobuf 3.19.6 which is incompatible.\ntensorflow-decision-forests 1.10.0 requires tensorflow==2.17.0, but you have tensorflow 2.11.0 which is incompatible.\ntensorflow-metadata 1.13.1 requires protobuf<5,>=3.20.3, but you have protobuf 3.19.6 which is incompatible.\ntensorflow-text 2.17.0 requires tensorflow<2.18,>=2.17.0, but you have tensorflow 2.11.0 which is incompatible.\ntf-keras 2.17.0 requires tensorflow<2.18,>=2.17, but you have tensorflow 2.11.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed gast-0.4.0 google-auth-oauthlib-0.4.6 keras-2.11.0 keras-embed-sim-0.10.0 keras-layer-normalization-0.16.0 keras-multi-head-0.29.0 keras-pos-embd-0.13.0 keras-position-wise-feed-forward-0.8.0 keras-self-attention-0.51.0 keras-transformer-0.40.0 keras_bert-0.89.0 ktrain-0.41.4 langdetect-1.0.9 protobuf-3.19.6 syntok-1.4.4 tensorboard-2.11.2 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.11.0 tensorflow-estimator-2.11.0 tika-2.6.0 tokenizers-0.13.3 transformers-4.28.1 whoosh-2.7.4\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import tensorflow as tf\nimport keras\nimport transformers\nprint(\"TensorFlow version:\", tf.__version__)\nprint(\"Transformers version:\", transformers.__version__)\nprint(\"Keras version:\", keras.__version__)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T09:05:00.301667Z","iopub.execute_input":"2025-01-29T09:05:00.301970Z","iopub.status.idle":"2025-01-29T09:05:07.841263Z","shell.execute_reply.started":"2025-01-29T09:05:00.301940Z","shell.execute_reply":"2025-01-29T09:05:07.840545Z"}},"outputs":[{"name":"stdout","text":"TensorFlow version: 2.11.0\nTransformers version: 4.28.1\nKeras version: 2.11.0\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"import pandas as pd\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\nfrom sklearn.metrics import accuracy_score, precision_recall_fscore_support\nimport numpy as np\nimport torch\nfrom torch.utils.data import Dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T09:05:07.842096Z","iopub.execute_input":"2025-01-29T09:05:07.842599Z","iopub.status.idle":"2025-01-29T09:05:14.858467Z","shell.execute_reply.started":"2025-01-29T09:05:07.842576Z","shell.execute_reply":"2025-01-29T09:05:14.857572Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# Load datasets\ntrain_df = pd.read_csv('/kaggle/input/ma-tam/AWM_train.csv')\ndev_df = pd.read_csv('/kaggle/input/ma-tam/AWM_dev.csv')\n# test_without_label = pd.read_csv('/kaggle/input/ma-tam/AWM_test_without_labels.csv')\ntest_with_label = pd.read_csv('/kaggle/input/malatestt/AWM_test_with_labels (1).csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T09:06:05.078304Z","iopub.execute_input":"2025-01-29T09:06:05.079048Z","iopub.status.idle":"2025-01-29T09:06:05.173726Z","shell.execute_reply.started":"2025-01-29T09:06:05.079013Z","shell.execute_reply":"2025-01-29T09:06:05.173107Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"test_with_label","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T09:06:05.469424Z","iopub.execute_input":"2025-01-29T09:06:05.469758Z","iopub.status.idle":"2025-01-29T09:06:05.507176Z","shell.execute_reply.started":"2025-01-29T09:06:05.469728Z","shell.execute_reply":"2025-01-29T09:06:05.506212Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"      id                                               Text        Class\n0      1  സൂരജ് നിന്റെ ആര് ആണ് ആള് ഇറക്കി പേടിപ്പിക്കുക ആണോ  Non-Abusive\n1      2  എത്ര അലക്കി വെളുപ്പിച്ചാലും നിനക്കു അർഹത ഇല്ലാ...      Abusive\n2      3  50 ലക്ഷം കയ്യിൽ വയ്ക്കാൻ ഒരിക്കലും യോഗ്യത ഇല്ല...  Non-Abusive\n3      4  \"ബിഗ് ബോസ്സിൽ നിങ്ങളുടെ അഭിനയം എന്തായിരുന്നു,മ...      Abusive\n4      5  അത് അങ്ങനെയാ നമ്മുടെ ഉള്ളിൽ നന്മ ഉണ്ടെങ്കിൽ പട...  Non-Abusive\n..   ...                                                ...          ...\n624  625           ഞാൻ ചെയ്ത വോട്ട് പാഴായില്ല. വളരെ സന്തോഷം  Non-Abusive\n625  626  സ്വന്തം കഴിവ് കൊണ്ടല്ല ജയിച്ചത് എന്നറിയുന്ന ദി...      Abusive\n626  627  റോബിൻ കഴിഞ്ഞാൽ ദിൽഷ തന്നെയാണ്   ഈ ട്രോഫിക്   അ...  Non-Abusive\n627  628  റോബിനെ കെട്ടണം. ഇല്ലെങ്കിൽ വോട്ടിട്ട അന്തം ഫാൻ...  Non-Abusive\n628  629  അതിൽ നിന്ന 4പേർ ഒഴികെ ബാക്കി എല്ലാവർക്കും റിയാ...  Non-Abusive\n\n[629 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>Text</th>\n      <th>Class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>സൂരജ് നിന്റെ ആര് ആണ് ആള് ഇറക്കി പേടിപ്പിക്കുക ആണോ</td>\n      <td>Non-Abusive</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>എത്ര അലക്കി വെളുപ്പിച്ചാലും നിനക്കു അർഹത ഇല്ലാ...</td>\n      <td>Abusive</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>50 ലക്ഷം കയ്യിൽ വയ്ക്കാൻ ഒരിക്കലും യോഗ്യത ഇല്ല...</td>\n      <td>Non-Abusive</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>\"ബിഗ് ബോസ്സിൽ നിങ്ങളുടെ അഭിനയം എന്തായിരുന്നു,മ...</td>\n      <td>Abusive</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>അത് അങ്ങനെയാ നമ്മുടെ ഉള്ളിൽ നന്മ ഉണ്ടെങ്കിൽ പട...</td>\n      <td>Non-Abusive</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>624</th>\n      <td>625</td>\n      <td>ഞാൻ ചെയ്ത വോട്ട് പാഴായില്ല. വളരെ സന്തോഷം</td>\n      <td>Non-Abusive</td>\n    </tr>\n    <tr>\n      <th>625</th>\n      <td>626</td>\n      <td>സ്വന്തം കഴിവ് കൊണ്ടല്ല ജയിച്ചത് എന്നറിയുന്ന ദി...</td>\n      <td>Abusive</td>\n    </tr>\n    <tr>\n      <th>626</th>\n      <td>627</td>\n      <td>റോബിൻ കഴിഞ്ഞാൽ ദിൽഷ തന്നെയാണ്   ഈ ട്രോഫിക്   അ...</td>\n      <td>Non-Abusive</td>\n    </tr>\n    <tr>\n      <th>627</th>\n      <td>628</td>\n      <td>റോബിനെ കെട്ടണം. ഇല്ലെങ്കിൽ വോട്ടിട്ട അന്തം ഫാൻ...</td>\n      <td>Non-Abusive</td>\n    </tr>\n    <tr>\n      <th>628</th>\n      <td>629</td>\n      <td>അതിൽ നിന്ന 4പേർ ഒഴികെ ബാക്കി എല്ലാവർക്കും റിയാ...</td>\n      <td>Non-Abusive</td>\n    </tr>\n  </tbody>\n</table>\n<p>629 rows × 3 columns</p>\n</div>"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"print(train_df.shape)\nprint(dev_df.shape)\nprint(test_with_label.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T09:06:05.842313Z","iopub.execute_input":"2025-01-29T09:06:05.842596Z","iopub.status.idle":"2025-01-29T09:06:05.847429Z","shell.execute_reply.started":"2025-01-29T09:06:05.842574Z","shell.execute_reply":"2025-01-29T09:06:05.846549Z"}},"outputs":[{"name":"stdout","text":"(2933, 2)\n(629, 2)\n(629, 3)\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"train_df.head(10)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T09:06:06.313414Z","iopub.execute_input":"2025-01-29T09:06:06.313712Z","iopub.status.idle":"2025-01-29T09:06:06.321711Z","shell.execute_reply.started":"2025-01-29T09:06:06.313689Z","shell.execute_reply":"2025-01-29T09:06:06.320930Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"                                                Text        Class\n0  നവ്യയുടെ കയ്യിന്ന് കിട്ടിയതാണല്ലോ. ഇവൾക്ക് അതൊ...      Abusive\n1  \"ഇവരുടെ പ്രശ്നം അസൂയ ആണ്, സുന്ദരികൾ ആയ നടിമാരോ...      Abusive\n2  ചുമ്മാതല്ല ഇവളെ പണ്ട് ലവർ അലക്കി വിട്ടത്...വായ...      Abusive\n3  \"ഒരു സിനിമയിൽ ജഗതി മദാമ്മയായിട്ട് വരുന്നുണ്ടല്...  Non-Abusive\n4  ഈ വർഷത്തെ ബൂലോക തോൽവി പരാജയം അതിനുള്ള ഓസ്‌ക്കാ...      Abusive\n5  ബാക്കിൽ നിക്കുന്ന ചേച്ചി : എന്ത് വെറുപ്പിക്കൽ ...      Abusive\n6  പ്രയാഗ  ശരിക്കും  അമേരിക്കൻ അമ്മായി ലുക്ക് ആയല...  Non-Abusive\n7  പ്രയാഗ ആർന്നോ ഞാൻ വിചാരിച്ചു ഏതോ ഇംഗ്ലീഷ് കാരി...  Non-Abusive\n8  ശെരിക്കും ഇതിന്റെ പാട്ട്  വട്ടാണ് വട്ടാണ് എനിക...  Non-Abusive\n9  നല്ല ഒരു നായിയായിരുന്നു പക്ഷേ ഇപ്പോ ആരും അഭിനയ...      Abusive","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Text</th>\n      <th>Class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>നവ്യയുടെ കയ്യിന്ന് കിട്ടിയതാണല്ലോ. ഇവൾക്ക് അതൊ...</td>\n      <td>Abusive</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>\"ഇവരുടെ പ്രശ്നം അസൂയ ആണ്, സുന്ദരികൾ ആയ നടിമാരോ...</td>\n      <td>Abusive</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ചുമ്മാതല്ല ഇവളെ പണ്ട് ലവർ അലക്കി വിട്ടത്...വായ...</td>\n      <td>Abusive</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>\"ഒരു സിനിമയിൽ ജഗതി മദാമ്മയായിട്ട് വരുന്നുണ്ടല്...</td>\n      <td>Non-Abusive</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ഈ വർഷത്തെ ബൂലോക തോൽവി പരാജയം അതിനുള്ള ഓസ്‌ക്കാ...</td>\n      <td>Abusive</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>ബാക്കിൽ നിക്കുന്ന ചേച്ചി : എന്ത് വെറുപ്പിക്കൽ ...</td>\n      <td>Abusive</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>പ്രയാഗ  ശരിക്കും  അമേരിക്കൻ അമ്മായി ലുക്ക് ആയല...</td>\n      <td>Non-Abusive</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>പ്രയാഗ ആർന്നോ ഞാൻ വിചാരിച്ചു ഏതോ ഇംഗ്ലീഷ് കാരി...</td>\n      <td>Non-Abusive</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>ശെരിക്കും ഇതിന്റെ പാട്ട്  വട്ടാണ് വട്ടാണ് എനിക...</td>\n      <td>Non-Abusive</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>നല്ല ഒരു നായിയായിരുന്നു പക്ഷേ ഇപ്പോ ആരും അഭിനയ...</td>\n      <td>Abusive</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"dev_df.head(10)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T09:06:08.749309Z","iopub.execute_input":"2025-01-29T09:06:08.749591Z","iopub.status.idle":"2025-01-29T09:06:08.757234Z","shell.execute_reply.started":"2025-01-29T09:06:08.749570Z","shell.execute_reply":"2025-01-29T09:06:08.756385Z"}},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"                                                Text        Class\n0  ഞാനും എന്റെ ഫാമിലി മോളെ വ്യക്തിത്വവും ഗെയിം കണ...  Non-Abusive\n1  സാരമില്ല മോളെ നീ ആരുടെ മുന്നിലും കരയരുത്  അത് ...  Non-Abusive\n2  ഡോക്ടർക്ക് ഇങ്ങനെ തന്നെ വേണം.  ഈ വിവരമില്ലാത്ത...      Abusive\n3  \"ട്രോളന്മാർക്കും, യൂട്യൂബ് ചാനൽസ് നും ചാകര ആയി .\"  Non-Abusive\n4  ഇപ്പോ പറഞ്ഞ നോ നേര്തെ പറഞ്ഞഗിൽ ഇത്തരം മോശം കമന...  Non-Abusive\n5  നിന്റെ ചേച്ചിമാർ ഓസിന് വോട്ട് പിടിച്ചപ്പോൾ ഓർക...  Non-Abusive\n6  നൈസ് ആയി ഒരു കാരണത്തിനു കാത്ത് നിൽക്കുക ആയിരുന...      Abusive\n7               അന്തം  ഫാൻസിനു  ഇനി  പിരിഞ്ഞു  പോവാം  Non-Abusive\n8  \"ഡോക്ടർ ഇത്രെയും ചീപ്പ്‌ ആയി പോയല്ലോ,,, ഇവന് ന...  Non-Abusive\n9  നല്ല രീതിയിൽ തീരേണ്ട ഒരു കാര്യമായിരുന്നു. ഇപ്പ...  Non-Abusive","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Text</th>\n      <th>Class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ഞാനും എന്റെ ഫാമിലി മോളെ വ്യക്തിത്വവും ഗെയിം കണ...</td>\n      <td>Non-Abusive</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>സാരമില്ല മോളെ നീ ആരുടെ മുന്നിലും കരയരുത്  അത് ...</td>\n      <td>Non-Abusive</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ഡോക്ടർക്ക് ഇങ്ങനെ തന്നെ വേണം.  ഈ വിവരമില്ലാത്ത...</td>\n      <td>Abusive</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>\"ട്രോളന്മാർക്കും, യൂട്യൂബ് ചാനൽസ് നും ചാകര ആയി .\"</td>\n      <td>Non-Abusive</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ഇപ്പോ പറഞ്ഞ നോ നേര്തെ പറഞ്ഞഗിൽ ഇത്തരം മോശം കമന...</td>\n      <td>Non-Abusive</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>നിന്റെ ചേച്ചിമാർ ഓസിന് വോട്ട് പിടിച്ചപ്പോൾ ഓർക...</td>\n      <td>Non-Abusive</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>നൈസ് ആയി ഒരു കാരണത്തിനു കാത്ത് നിൽക്കുക ആയിരുന...</td>\n      <td>Abusive</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>അന്തം  ഫാൻസിനു  ഇനി  പിരിഞ്ഞു  പോവാം</td>\n      <td>Non-Abusive</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>\"ഡോക്ടർ ഇത്രെയും ചീപ്പ്‌ ആയി പോയല്ലോ,,, ഇവന് ന...</td>\n      <td>Non-Abusive</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>നല്ല രീതിയിൽ തീരേണ്ട ഒരു കാര്യമായിരുന്നു. ഇപ്പ...</td>\n      <td>Non-Abusive</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"test_with_label.head(10)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T09:06:09.219966Z","iopub.execute_input":"2025-01-29T09:06:09.220192Z","iopub.status.idle":"2025-01-29T09:06:09.228222Z","shell.execute_reply.started":"2025-01-29T09:06:09.220174Z","shell.execute_reply":"2025-01-29T09:06:09.227467Z"}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"   id                                               Text        Class\n0   1  സൂരജ് നിന്റെ ആര് ആണ് ആള് ഇറക്കി പേടിപ്പിക്കുക ആണോ  Non-Abusive\n1   2  എത്ര അലക്കി വെളുപ്പിച്ചാലും നിനക്കു അർഹത ഇല്ലാ...      Abusive\n2   3  50 ലക്ഷം കയ്യിൽ വയ്ക്കാൻ ഒരിക്കലും യോഗ്യത ഇല്ല...  Non-Abusive\n3   4  \"ബിഗ് ബോസ്സിൽ നിങ്ങളുടെ അഭിനയം എന്തായിരുന്നു,മ...      Abusive\n4   5  അത് അങ്ങനെയാ നമ്മുടെ ഉള്ളിൽ നന്മ ഉണ്ടെങ്കിൽ പട...  Non-Abusive\n5   6  ഇനി കൂടുതൽ ഒന്നും പറയാതിരിക്കുന്നതായിരിക്കും ന...  Non-Abusive\n6   7  നിങ്ങളെ ആരും ഇഷ്ടപ്പെടുന്നില്ലാ നിങ്ങളുടെ കാര്...      Abusive\n7   8  ഈ ഞാൻ ഞാൻ ...... ഞാനെന്താണെന്ന് മനസ്സിലായി ......      Abusive\n8   9                       ഇതിൻ്റെ ട്രോൾ കാണാൻ കേറി വരൂ  Non-Abusive\n9  10      പണത്തിന്റെ കാര്യം വന്നപ്പോൾ ദേഷ്യം ഒക്കെ പോയോ  Non-Abusive","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>Text</th>\n      <th>Class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>സൂരജ് നിന്റെ ആര് ആണ് ആള് ഇറക്കി പേടിപ്പിക്കുക ആണോ</td>\n      <td>Non-Abusive</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>എത്ര അലക്കി വെളുപ്പിച്ചാലും നിനക്കു അർഹത ഇല്ലാ...</td>\n      <td>Abusive</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>50 ലക്ഷം കയ്യിൽ വയ്ക്കാൻ ഒരിക്കലും യോഗ്യത ഇല്ല...</td>\n      <td>Non-Abusive</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>\"ബിഗ് ബോസ്സിൽ നിങ്ങളുടെ അഭിനയം എന്തായിരുന്നു,മ...</td>\n      <td>Abusive</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>അത് അങ്ങനെയാ നമ്മുടെ ഉള്ളിൽ നന്മ ഉണ്ടെങ്കിൽ പട...</td>\n      <td>Non-Abusive</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>6</td>\n      <td>ഇനി കൂടുതൽ ഒന്നും പറയാതിരിക്കുന്നതായിരിക്കും ന...</td>\n      <td>Non-Abusive</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>7</td>\n      <td>നിങ്ങളെ ആരും ഇഷ്ടപ്പെടുന്നില്ലാ നിങ്ങളുടെ കാര്...</td>\n      <td>Abusive</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>8</td>\n      <td>ഈ ഞാൻ ഞാൻ ...... ഞാനെന്താണെന്ന് മനസ്സിലായി ......</td>\n      <td>Abusive</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>9</td>\n      <td>ഇതിൻ്റെ ട്രോൾ കാണാൻ കേറി വരൂ</td>\n      <td>Non-Abusive</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>10</td>\n      <td>പണത്തിന്റെ കാര്യം വന്നപ്പോൾ ദേഷ്യം ഒക്കെ പോയോ</td>\n      <td>Non-Abusive</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"import re\nfrom bs4 import BeautifulSoup\ndef remove_punctuations(text):\n    punctuations = '''!()-[]{};:'\"“\\’,<>./?@#$%^&*_~—॥'''\n    return ''.join([char for char in text if char not in punctuations])\n\n# Function to replace unwanted strings (URLs, emojis, HTML tags, etc.)\ndef replace_strings(text):\n    # Remove URLs\n    url_pattern = r'https?://\\S+|www\\.\\S+'\n    text = re.sub(url_pattern, ' ', text)\n\n    # Remove emojis\n    emoji_pattern = re.compile(\"[\" \n        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n        u\"\\U00002702-\\U000027B0\"\n        u\"\\U000024C2-\\U0001F251\"  \n        u\"\\u2000-\\u206F\"          # general punctuations\n        \"]+\", flags=re.UNICODE)\n    text = emoji_pattern.sub(r' ', text)\n\n    # Remove HTML tags\n    text = BeautifulSoup(text, 'html.parser').get_text()\n\n    # Normalize spaces\n    text = re.sub(r'\\s+', ' ', text)\n\n    return text\n\n# Function for full preprocessing\ndef preprocessing(text):\n    cleaned_text = remove_punctuations(replace_strings(text))\n    return cleaned_text.lower()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T09:06:10.918380Z","iopub.execute_input":"2025-01-29T09:06:10.918675Z","iopub.status.idle":"2025-01-29T09:06:11.201172Z","shell.execute_reply.started":"2025-01-29T09:06:10.918653Z","shell.execute_reply":"2025-01-29T09:06:11.200542Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"# Apply preprocessing to all datasets\ntrain_df['cleanText'] = train_df['Text'].apply(lambda x: preprocessing(str(x)))\ndev_df['cleanText'] = dev_df['Text'].apply(lambda x: preprocessing(str(x)))\ntest_with_label['cleanText'] = test_with_label['Text'].apply(lambda x: preprocessing(str(x)))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T09:06:12.527073Z","iopub.execute_input":"2025-01-29T09:06:12.527789Z","iopub.status.idle":"2025-01-29T09:06:12.844891Z","shell.execute_reply.started":"2025-01-29T09:06:12.527753Z","shell.execute_reply":"2025-01-29T09:06:12.843960Z"}},"outputs":[{"name":"stderr","text":"<ipython-input-12-e98d2e6d74aa>:26: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n  text = BeautifulSoup(text, 'html.parser').get_text()\n<ipython-input-12-e98d2e6d74aa>:26: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n  text = BeautifulSoup(text, 'html.parser').get_text()\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"# Combine all text for vocabulary analysis\ntrain_corpus = train_df['cleanText'].sum()\ndev_corpus = dev_df['cleanText'].sum()\ntest_corpus = test_with_label['cleanText'].sum()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T09:06:12.931267Z","iopub.execute_input":"2025-01-29T09:06:12.931766Z","iopub.status.idle":"2025-01-29T09:06:12.980895Z","shell.execute_reply.started":"2025-01-29T09:06:12.931730Z","shell.execute_reply":"2025-01-29T09:06:12.979892Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"# Vocabulary and OOV analysis\ntrain_vocab = set(train_corpus.split())\ndev_vocab = set(dev_corpus.split())\ntest_vocab = set(test_corpus.split())\n\noov_dev = dev_vocab - train_vocab\noov_test = test_vocab - train_vocab\n\nprint(f\"Number of unique words in training data: {len(train_vocab)}\")\nprint(f\"Number of unique words in development data: {len(dev_vocab)}\")\nprint(f\"Number of unique words in test data: {len(test_vocab)}\")\nprint(f\"OOV words in dev dataset: {len(oov_dev)}\")\nprint(f\"OOV words in test dataset: {len(oov_test)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T09:06:13.348200Z","iopub.execute_input":"2025-01-29T09:06:13.348538Z","iopub.status.idle":"2025-01-29T09:06:13.368890Z","shell.execute_reply.started":"2025-01-29T09:06:13.348495Z","shell.execute_reply":"2025-01-29T09:06:13.367955Z"}},"outputs":[{"name":"stdout","text":"Number of unique words in training data: 15675\nNumber of unique words in development data: 4647\nNumber of unique words in test data: 4586\nOOV words in dev dataset: 2525\nOOV words in test dataset: 2496\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"# Label encoding for train and dev datasets\ntrain_df['enc_label'] = train_df['Class'].replace({'Abusive': 1, 'Non-Abusive': 0})\ndev_df['enc_label'] = dev_df['Class'].replace({'Abusive': 1, 'Non-Abusive': 0})\n\nprint(\"Training dataset label counts:\")\nprint(train_df['enc_label'].value_counts())\nprint(\"Development dataset label counts:\")\nprint(dev_df['enc_label'].value_counts())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T09:06:14.995014Z","iopub.execute_input":"2025-01-29T09:06:14.995326Z","iopub.status.idle":"2025-01-29T09:06:15.017889Z","shell.execute_reply.started":"2025-01-29T09:06:14.995299Z","shell.execute_reply":"2025-01-29T09:06:15.017069Z"}},"outputs":[{"name":"stdout","text":"Training dataset label counts:\nenc_label\n1    1531\n0    1402\nName: count, dtype: int64\nDevelopment dataset label counts:\nenc_label\n0    326\n1    303\nName: count, dtype: int64\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-16-7f70e88776ca>:2: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n  train_df['enc_label'] = train_df['Class'].replace({'Abusive': 1, 'Non-Abusive': 0})\n<ipython-input-16-7f70e88776ca>:3: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n  dev_df['enc_label'] = dev_df['Class'].replace({'Abusive': 1, 'Non-Abusive': 0})\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"%reload_ext autoreload\n%autoreload 2\n%matplotlib inline\nimport os\nos.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T09:06:16.737104Z","iopub.execute_input":"2025-01-29T09:06:16.737389Z","iopub.status.idle":"2025-01-29T09:06:16.812032Z","shell.execute_reply.started":"2025-01-29T09:06:16.737365Z","shell.execute_reply":"2025-01-29T09:06:16.811423Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"# Import necessary libraries\nimport ktrain\nfrom ktrain import text","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T09:06:17.113357Z","iopub.execute_input":"2025-01-29T09:06:17.113656Z","iopub.status.idle":"2025-01-29T09:06:18.299844Z","shell.execute_reply.started":"2025-01-29T09:06:17.113630Z","shell.execute_reply":"2025-01-29T09:06:18.298976Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"categories=['Abusive','Non-Abusive']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T09:06:18.932319Z","iopub.execute_input":"2025-01-29T09:06:18.932644Z","iopub.status.idle":"2025-01-29T09:06:18.996423Z","shell.execute_reply.started":"2025-01-29T09:06:18.932616Z","shell.execute_reply":"2025-01-29T09:06:18.995792Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\n# Set random seed for reproducibility\nnp.random.seed(42)\ntf.random.set_seed(42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T09:06:19.417712Z","iopub.execute_input":"2025-01-29T09:06:19.417999Z","iopub.status.idle":"2025-01-29T09:06:19.480231Z","shell.execute_reply.started":"2025-01-29T09:06:19.417977Z","shell.execute_reply":"2025-01-29T09:06:19.479602Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"# Training data\nX_train = train_df['cleanText']  # Preprocessed text column\ny_train = train_df['Class']  # Labels for training\n\n# Validation data\nX_valid = dev_df['cleanText']  # Preprocessed text column\ny_valid = dev_df['Class']  # Labels for validation\n\n# Test data (without labels)\nX_test = test_with_label['cleanText']  # Preprocessed text column\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T09:06:21.443950Z","iopub.execute_input":"2025-01-29T09:06:21.444274Z","iopub.status.idle":"2025-01-29T09:06:21.508574Z","shell.execute_reply.started":"2025-01-29T09:06:21.444245Z","shell.execute_reply":"2025-01-29T09:06:21.507912Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"# Convert text and labels to lists for ktrain preprocessing\nX_train_list = X_train.tolist()\ny_train_list = y_train.tolist()\nX_valid_list = X_valid.tolist()\ny_valid_list = y_valid.tolist()\nX_test_list = X_test.tolist()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T09:06:24.054782Z","iopub.execute_input":"2025-01-29T09:06:24.055114Z","iopub.status.idle":"2025-01-29T09:06:24.120610Z","shell.execute_reply.started":"2025-01-29T09:06:24.055087Z","shell.execute_reply":"2025-01-29T09:06:24.119762Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"model_name = 'Hate-speech-CNERG/indic-abusive-allInOne-MuRIL'\ntrans = text.Transformer(model_name,maxlen=128,class_names=categories)\nprint(\"Preprocessing train data...\")\ntrain = trans.preprocess_train(X_train_list, y_train_list)\n\nprint(\"Preprocessing validation data...\")\nvalid = trans.preprocess_test(X_valid_list, y_valid_list)\n\nprint(\"Preprocessing test data...\")\ntest = trans.preprocess_test(X_test_list)  # No labels for test data\n\nmodel = trans.get_classifier()\nlearner = ktrain.get_learner(model, train_data=train,val_data=valid, batch_size=16)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T09:06:26.349846Z","iopub.execute_input":"2025-01-29T09:06:26.350189Z","iopub.status.idle":"2025-01-29T09:06:48.439746Z","shell.execute_reply.started":"2025-01-29T09:06:26.350164Z","shell.execute_reply":"2025-01-29T09:06:48.439093Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/709 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0632b72c1d6e4ca491316c7a50248464"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/950M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0d18392e6ce94864baf185c7e873e412"}},"metadata":{}},{"name":"stdout","text":"Preprocessing train data...\npreprocessing train...\nlanguage: ml\ntrain sequence lengths:\n\tmean : 15\n\t95percentile : 40\n\t99percentile : 69\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/ktrain/utils.py:744: UserWarning: class_names argument was ignored, as they were extracted from string labels in dataset\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/525 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4b42cb627df54780b5ee70a5561e2df4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/3.16M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"89623f0311e34a67b435452b9fd13904"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f15039542e0d4b209dbd2f75d89cf624"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"Is Multi-Label? False\nPreprocessing validation data...\npreprocessing test...\nlanguage: ml\ntest sequence lengths:\n\tmean : 17\n\t95percentile : 46\n\t99percentile : 75\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"Preprocessing test data...\npreprocessing test...\nlanguage: ml\ntest sequence lengths:\n\tmean : 17\n\t95percentile : 46\n\t99percentile : 79\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}}],"execution_count":23},{"cell_type":"code","source":"learner.fit_onecycle(1e-5,8)  ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T09:06:50.731573Z","iopub.execute_input":"2025-01-29T09:06:50.731978Z","iopub.status.idle":"2025-01-29T12:40:35.027350Z","shell.execute_reply.started":"2025-01-29T09:06:50.731855Z","shell.execute_reply":"2025-01-29T12:40:35.026400Z"}},"outputs":[{"name":"stdout","text":"\n\nbegin training using onecycle policy with max lr of 1e-05...\nEpoch 1/8\n184/184 [==============================] - 1638s 9s/step - loss: 1.1071 - accuracy: 0.4511 - val_loss: 0.7849 - val_accuracy: 0.4293\nEpoch 2/8\n184/184 [==============================] - 1611s 9s/step - loss: 0.7221 - accuracy: 0.4616 - val_loss: 0.7033 - val_accuracy: 0.4944\nEpoch 3/8\n184/184 [==============================] - 1605s 9s/step - loss: 0.6930 - accuracy: 0.5274 - val_loss: 0.6834 - val_accuracy: 0.5644\nEpoch 4/8\n184/184 [==============================] - 1594s 9s/step - loss: 0.6641 - accuracy: 0.6048 - val_loss: 0.5946 - val_accuracy: 0.6916\nEpoch 5/8\n184/184 [==============================] - 1586s 9s/step - loss: 0.5970 - accuracy: 0.6833 - val_loss: 0.5755 - val_accuracy: 0.6884\nEpoch 6/8\n184/184 [==============================] - 1602s 9s/step - loss: 0.4953 - accuracy: 0.7661 - val_loss: 0.5601 - val_accuracy: 0.7250\nEpoch 7/8\n184/184 [==============================] - 1597s 9s/step - loss: 0.3947 - accuracy: 0.8268 - val_loss: 0.6111 - val_accuracy: 0.7091\nEpoch 8/8\n184/184 [==============================] - 1591s 9s/step - loss: 0.3367 - accuracy: 0.8684 - val_loss: 0.6055 - val_accuracy: 0.7297\n","output_type":"stream"},{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"<keras.callbacks.History at 0x78a9c1715ff0>"},"metadata":{}}],"execution_count":24},{"cell_type":"code","source":"from sklearn.metrics import classification_report\nimport numpy as np\n\n# Step 1: Preprocess the test data using the same transformer used for training and validation\ntest_data = trans.preprocess_test(X_test_list)  # Preprocessed test data (this converts it into a TransformerDataset)\n\n# Step 2: Get predictions for the test data (this returns probabilities)\npreds = learner.predict(test_data)\n\n# Step 3: Convert probabilities to class labels (0 or 1 based on max probability)\npred_labels = np.argmax(preds, axis=1)  \n# Convert true labels from strings to numeric format (matching predicted labels)\ny_test_true = [1 if label == 'Abusive' else 0 for label in y_test_true]\n\n# Generate classification report\nreport = classification_report(y_test_true, pred_labels, target_names=categories)\nprint(report)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T12:59:45.927291Z","iopub.execute_input":"2025-01-29T12:59:45.927630Z","iopub.status.idle":"2025-01-29T13:01:50.395744Z","shell.execute_reply.started":"2025-01-29T12:59:45.927606Z","shell.execute_reply":"2025-01-29T13:01:50.394781Z"}},"outputs":[{"name":"stdout","text":"preprocessing test...\nlanguage: ml\ntest sequence lengths:\n\tmean : 17\n\t95percentile : 46\n\t99percentile : 79\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"629/629 [==============================] - 124s 197ms/step\n              precision    recall  f1-score   support\n\n     Abusive       1.00      0.45      0.62       629\n Non-Abusive       0.00      0.00      0.00         0\n\n    accuracy                           0.45       629\n   macro avg       0.50      0.22      0.31       629\nweighted avg       1.00      0.45      0.62       629\n\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"}],"execution_count":33}]}